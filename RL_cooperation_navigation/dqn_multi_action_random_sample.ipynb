{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "\n",
    "class ENV:\n",
    "    def __init__(self, map_size, obs_pos1, obs_pos2, robot_start_pos, goal_pos):\n",
    "        self.map_size = map_size # integer\n",
    "        self.obs_pos1 = obs_pos1 # [a,b], 2by1 list\n",
    "        self.obs_pos2 = obs_pos2 # [a,b], 2by1 list\n",
    "        self.goal_pos = goal_pos\n",
    "        self.robot_pos1 = robot_start_pos[0:2] #[a,b] 2by1 list\n",
    "        self.robot_pos2 = robot_start_pos[2:4]\n",
    "        # set the walls\n",
    "        self.fig = plt.figure()\n",
    "        ax = plt.axes(xlim=(-0.5,self.map_size), ylim=(-0.5,self.map_size))  \n",
    "        #self.render_env()\n",
    "    def render_env(self):        \n",
    "        # draw the obstacles and goal\n",
    "        obs1 = plt.scatter(self.obs_pos1[0], self.obs_pos1[1], c='r', marker = 's', linewidths = 5) # have to check whether we can receive <list or np.array>        \n",
    "        obs2 = plt.scatter(self.obs_pos2[0], self.obs_pos2[1], c='r', marker = 's', linewidths = 5)\n",
    "        goal = plt.scatter(self.goal_pos[0], self.goal_pos[1], c='g', marker='x', linewidths = 4)\n",
    "        # draw the robot                \n",
    "        ro1 = plt.scatter(self.robot_pos1[0], self.robot_pos1[1], c='b', linewidths = 3)\n",
    "        ro2 = plt.scatter(self.robot_pos2[0], self.robot_pos2[1], c='b', linewidths = 3)        \n",
    "        self.fig.canvas.draw()   \n",
    "        sleep(0.2)\n",
    "        ro1.remove()\n",
    "        ro2.remove()        \n",
    "    def update(self, robot_current_pos):\n",
    "        self.robot_pos1 = robot_current_pos[0:2]\n",
    "        self.robot_pos2 = robot_current_pos[2:4]        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./dqn_multi_reward_easy_500.ckpt\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode     0]  total reward: -419.744626502     steps:   500    q:-11.9557304382, failure\n",
      "[Episode     1]  total reward: -67.0402747168     steps:   500    q:-28.2305870056, failure\n",
      "[Episode     2]  total reward: -330.717790742     steps:   500    q:-26.8924407959, failure\n",
      "[Episode     3]  total reward: -136.813156577     steps:   500    q:-44.4332199097, failure\n",
      "[Episode     4]  total reward: -117.113903241     steps:   500    q:-64.8000030518, failure\n",
      "[Episode     5]  total reward: -64.343982006     steps:   500    q:-53.1013298035, failure\n",
      "[Episode     6]  total reward: -346.284768105     steps:   500    q:-90.561668396, failure\n",
      "[Episode     7]  total reward: -309.432172739    steps:   463    q:-79.864151001, success\n",
      "[Episode     8]  total reward: -162.782653411     steps:   500    q:-64.3104171753, failure\n",
      "[Episode     9]  total reward: -98.443486299     steps:   500    q:-70.1088943481, failure\n",
      "[Episode    10]  total reward: -241.760195027     steps:   500    q:-80.8323974609, failure\n",
      "[Episode    11]  total reward: 411.933115753    steps:    39    q:-20.9332675934, success\n",
      "[Episode    12]  total reward: 43.4909167429    steps:    80    q:-49.7827453613, success\n",
      "[Episode    13]  total reward: -432.933452894    steps:   207    q:-85.8720092773, success\n",
      "[Episode    14]  total reward: -165.748679633     steps:   500    q:-76.4775085449, failure\n",
      "[Episode    15]  total reward: -73.0812299924     steps:   500    q:-91.6462249756, failure\n",
      "[Episode    16]  total reward: -161.312257973     steps:   500    q:-97.4094161987, failure\n",
      "[Episode    17]  total reward: -354.399048262     steps:   500    q:-88.2680587769, failure\n",
      "[Episode    18]  total reward: -88.2783375987     steps:   500    q:-33.6510391235, failure\n",
      "[Episode    19]  total reward: -61.0716520338     steps:   500    q:-21.4143009186, failure\n",
      "[Episode    20]  total reward: -175.188436104     steps:   500    q:-117.94543457, failure\n",
      "[Episode    21]  total reward: -93.8941837421     steps:   500    q:-35.5784950256, failure\n",
      "[Episode    22]  total reward: 526.669659662    steps:    26    q:167.393585205, success\n",
      "[Episode    23]  total reward: -138.114577357     steps:   500    q:68.1506118774, failure\n",
      "[Episode    24]  total reward: -224.602079688     steps:   500    q:-84.7983932495, failure\n",
      "[Episode    25]  total reward: -22.1865156712    steps:    89    q:464.85043335, success\n",
      "[Episode    26]  total reward: -324.218308539    steps:   252    q:93.05884552, success\n",
      "[Episode    27]  total reward: -329.635235645     steps:   500    q:23.8935089111, failure\n",
      "[Episode    28]  total reward: -394.28902494    steps:   235    q:151.351242065, success\n",
      "[Episode    29]  total reward: -293.307934489    steps:   221    q:152.59463501, success\n",
      "[Episode    30]  total reward: -64.0996807054     steps:   500    q:53.4512405396, failure\n",
      "[Episode    31]  total reward: -459.424299884     steps:   500    q:198.875778198, failure\n",
      "[Episode    32]  total reward: -354.794468287     steps:   500    q:36.8437385559, failure\n",
      "[Episode    33]  total reward: -206.3062176     steps:   500    q:96.6720123291, failure\n",
      "[Episode    34]  total reward: -369.430864507     steps:   500    q:121.987548828, failure\n",
      "[Episode    35]  total reward: -378.320436117     steps:   500    q:115.645690918, failure\n",
      "[Episode    36]  total reward: -467.202240558     steps:   500    q:94.1417694092, failure\n",
      "[Episode    37]  total reward: -97.979872117     steps:   500    q:61.0186462402, failure\n",
      "[Episode    38]  total reward: -231.366799142     steps:   500    q:-13.4959182739, failure\n",
      "[Episode    39]  total reward: -136.943082567     steps:   500    q:-42.0807647705, failure\n",
      "[Episode    40]  total reward: -304.385384162     steps:   500    q:204.691329956, failure\n",
      "[Episode    41]  total reward: -207.290943173     steps:   500    q:289.125061035, failure\n",
      "[Episode    42]  total reward: -373.42653408     steps:   500    q:47.456817627, failure\n",
      "[Episode    43]  total reward: -320.614976551     steps:   500    q:62.8492431641, failure\n",
      "[Episode    44]  total reward: -203.601439229     steps:   500    q:-24.8884792328, failure\n",
      "[Episode    45]  total reward: -262.739783593     steps:   500    q:-56.095287323, failure\n",
      "[Episode    46]  total reward: -314.371769395     steps:   500    q:-53.6521530151, failure\n",
      "[Episode    47]  total reward: -249.20971577     steps:   500    q:-42.0104598999, failure\n",
      "[Episode    48]  total reward: -325.702749124     steps:   500    q:-51.9296913147, failure\n",
      "[Episode    49]  total reward: -246.343291634    steps:   413    q:-35.3470802307, success\n",
      "[Episode    50]  total reward: -324.72737021     steps:   500    q:-60.2651405334, failure\n",
      "[Episode    51]  total reward: -207.433460872     steps:   500    q:-36.2678642273, failure\n",
      "[Episode    52]  total reward: -283.476302724    steps:   129    q:24.3554363251, success\n",
      "[Episode    53]  total reward: -61.867319608     steps:   500    q:-40.1061859131, failure\n",
      "[Episode    54]  total reward: -173.089145136     steps:   500    q:-63.4425010681, failure\n",
      "[Episode    55]  total reward: -48.3502444386     steps:   500    q:-61.7798042297, failure\n",
      "[Episode    56]  total reward: -122.613164134     steps:   500    q:-76.5556106567, failure\n",
      "[Episode    57]  total reward: -234.121396332     steps:   500    q:-91.4376068115, failure\n",
      "[Episode    58]  total reward: -338.840056968     steps:   500    q:-99.9500274658, failure\n",
      "[Episode    59]  total reward: -167.535958023     steps:   500    q:-50.3568572998, failure\n",
      "[Episode    60]  total reward: 708.041648664    steps:    17    q:273.452880859, success\n",
      "[Episode    61]  total reward: -75.7094494875    steps:   213    q:88.2200393677, success\n",
      "[Episode    62]  total reward: -572.196878892     steps:   500    q:83.2469787598, failure\n",
      "[Episode    63]  total reward: -399.119558398     steps:   500    q:83.5542755127, failure\n",
      "[Episode    64]  total reward: -478.287462716     steps:   500    q:194.727935791, failure\n",
      "[Episode    65]  total reward: -51.0483127964     steps:   500    q:-60.1149215698, failure\n",
      "[Episode    66]  total reward: -236.55633973     steps:   500    q:-85.684715271, failure\n",
      "[Episode    67]  total reward: -256.078259425     steps:   500    q:4.59517192841, failure\n",
      "[Episode    68]  total reward: -353.36094695     steps:   500    q:-60.672088623, failure\n",
      "[Episode    69]  total reward: -44.7117753133    steps:   275    q:196.950668335, success\n",
      "[Episode    70]  total reward: -103.613335736     steps:   500    q:-24.5449371338, failure\n",
      "[Episode    71]  total reward: -313.100556184     steps:   500    q:-45.5826568604, failure\n",
      "[Episode    72]  total reward: -45.6524958812     steps:   500    q:-12.2952346802, failure\n",
      "[Episode    73]  total reward: -202.762349496    steps:   471    q:65.890838623, success\n",
      "[Episode    74]  total reward: -120.120719412     steps:   500    q:-11.6881952286, failure\n",
      "[Episode    75]  total reward: -161.508611501     steps:   500    q:-57.8263778687, failure\n",
      "[Episode    76]  total reward: -362.753794827     steps:   500    q:-98.9570007324, failure\n",
      "[Episode    77]  total reward: -149.07183399     steps:   500    q:-44.5600128174, failure\n",
      "[Episode    78]  total reward: -318.943045615     steps:   500    q:-32.6324996948, failure\n",
      "[Episode    79]  total reward: -50.3417929804     steps:   500    q:-17.0251998901, failure\n",
      "[Episode    80]  total reward: -413.514776565     steps:   500    q:-58.7927703857, failure\n",
      "[Episode    81]  total reward: -262.61043503     steps:   500    q:-77.2743606567, failure\n",
      "[Episode    82]  total reward: -264.23733052     steps:   500    q:-73.122177124, failure\n",
      "[Episode    83]  total reward: -446.959179011     steps:   500    q:-80.6949081421, failure\n",
      "[Episode    84]  total reward: -461.788528232     steps:   500    q:-101.170906067, failure\n",
      "[Episode    85]  total reward: -302.74719243     steps:   500    q:-11.3653106689, failure\n",
      "[Episode    86]  total reward: -304.648021541     steps:   500    q:-22.5492687225, failure\n",
      "[Episode    87]  total reward: -389.556019284     steps:   500    q:-61.9882049561, failure\n",
      "[Episode    88]  total reward: -349.102689699     steps:   500    q:-34.4560699463, failure\n",
      "[Episode    89]  total reward: -350.696223738     steps:   500    q:-70.5370788574, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode    90]  total reward: -392.173063676     steps:   500    q:-118.904579163, failure\n",
      "[Episode    91]  total reward: -138.510663296     steps:   500    q:-95.3542785645, failure\n",
      "[Episode    92]  total reward: -330.827598648     steps:   500    q:-93.028793335, failure\n",
      "[Episode    93]  total reward: -529.552476873     steps:   500    q:-75.7586212158, failure\n",
      "[Episode    94]  total reward: -402.290384006     steps:   500    q:-138.994827271, failure\n",
      "[Episode    95]  total reward: -622.676494489     steps:   500    q:-123.739906311, failure\n",
      "[Episode    96]  total reward: -435.72183739     steps:   500    q:-92.6995544434, failure\n",
      "[Episode    97]  total reward: -303.462160313     steps:   500    q:-87.3437271118, failure\n",
      "[Episode    98]  total reward: -428.236424026     steps:   500    q:-70.2235717773, failure\n",
      "[Episode    99]  total reward: -440.825546691     steps:   500    q:-98.8034973145, failure\n",
      "[Episode   100]  total reward: -306.56857408     steps:   500    q:-97.3634109497, failure\n",
      "[Episode   101]  total reward: -175.597984053     steps:   500    q:-99.7757644653, failure\n",
      "[Episode   102]  total reward: -467.598434804     steps:   500    q:-241.951751709, failure\n",
      "[Episode   103]  total reward: -492.628712053     steps:   500    q:-128.594741821, failure\n",
      "[Episode   104]  total reward: -424.779702066     steps:   500    q:-115.053985596, failure\n",
      "[Episode   105]  total reward: -116.234607619     steps:   500    q:-22.0326366425, failure\n",
      "[Episode   106]  total reward: -548.265361319     steps:   500    q:-143.48425293, failure\n",
      "[Episode   107]  total reward: -133.961787815     steps:   500    q:-141.62713623, failure\n",
      "[Episode   108]  total reward: -253.315550188     steps:   500    q:-136.49269104, failure\n",
      "[Episode   109]  total reward: -378.47684717     steps:   500    q:-195.214279175, failure\n",
      "[Episode   110]  total reward: -448.143292365     steps:   500    q:-170.723556519, failure\n",
      "[Episode   111]  total reward: -359.516938229     steps:   500    q:-77.0741271973, failure\n",
      "[Episode   112]  total reward: -115.575708713     steps:   500    q:-19.4252567291, failure\n",
      "[Episode   113]  total reward: -400.081318531     steps:   500    q:-72.6769638062, failure\n",
      "[Episode   114]  total reward: -313.287411052     steps:   500    q:-95.3337631226, failure\n",
      "[Episode   115]  total reward: -412.783902954     steps:   500    q:-188.87840271, failure\n",
      "[Episode   116]  total reward: -255.560788633     steps:   500    q:13.5107297897, failure\n",
      "[Episode   117]  total reward: -274.355013427     steps:   500    q:-11.982673645, failure\n",
      "[Episode   118]  total reward: -282.564321566     steps:   500    q:-119.728500366, failure\n",
      "[Episode   119]  total reward: -209.044025663     steps:   500    q:-98.1440505981, failure\n",
      "[Episode   120]  total reward: -385.048724221     steps:   500    q:-160.047683716, failure\n",
      "[Episode   121]  total reward: -234.351071418     steps:   500    q:-127.483795166, failure\n",
      "[Episode   122]  total reward: -484.425854729     steps:   500    q:-198.019165039, failure\n",
      "[Episode   123]  total reward: -33.4156306359     steps:   500    q:-145.904998779, failure\n",
      "[Episode   124]  total reward: -228.76982028     steps:   500    q:-158.336746216, failure\n",
      "[Episode   125]  total reward: -363.808007333     steps:   500    q:-170.52166748, failure\n",
      "[Episode   126]  total reward: 649.514424743    steps:    20    q:-34.3466300964, success\n",
      "[Episode   127]  total reward: -316.758239966     steps:   500    q:-175.703384399, failure\n",
      "[Episode   128]  total reward: -305.95425539     steps:   500    q:-107.121902466, failure\n",
      "[Episode   129]  total reward: -181.555581438     steps:   500    q:-140.549407959, failure\n",
      "[Episode   130]  total reward: 678.843935136    steps:    17    q:44.2079620361, success\n",
      "[Episode   131]  total reward: -30.6143735601     steps:   500    q:-153.156509399, failure\n",
      "[Episode   132]  total reward: 34.079332124    steps:   115    q:15.8234548569, success\n",
      "[Episode   133]  total reward: -295.108272962     steps:   500    q:-141.307388306, failure\n",
      "[Episode   134]  total reward: -332.406409953     steps:   500    q:-154.892349243, failure\n",
      "[Episode   135]  total reward: -468.344072219     steps:   500    q:-158.763046265, failure\n",
      "[Episode   136]  total reward: -113.223260972     steps:   500    q:-111.217346191, failure\n",
      "[Episode   137]  total reward: -31.3162842674     steps:   500    q:-124.69683075, failure\n",
      "[Episode   138]  total reward: -484.152895682     steps:   500    q:-136.224121094, failure\n",
      "[Episode   139]  total reward: -434.069991631    steps:   271    q:-144.285568237, success\n",
      "[Episode   140]  total reward: -427.521030032     steps:   500    q:-163.298446655, failure\n",
      "[Episode   141]  total reward: -199.749198264     steps:   500    q:-108.701301575, failure\n",
      "[Episode   142]  total reward: -89.514483939     steps:   500    q:47.142829895, failure\n",
      "[Episode   143]  total reward: -468.227110928     steps:   500    q:-177.472381592, failure\n",
      "[Episode   144]  total reward: -386.577393921     steps:   500    q:-139.303939819, failure\n",
      "[Episode   145]  total reward: -364.177578744     steps:   500    q:-133.14956665, failure\n",
      "[Episode   146]  total reward: -258.103823773     steps:   500    q:-109.563796997, failure\n",
      "[Episode   147]  total reward: -464.673412563     steps:   500    q:-133.855224609, failure\n",
      "[Episode   148]  total reward: -531.636670174     steps:   500    q:-166.245880127, failure\n",
      "[Episode   149]  total reward: -470.984654884     steps:   500    q:-128.844985962, failure\n",
      "[Episode   150]  total reward: -615.608000929     steps:   500    q:-178.165908813, failure\n",
      "[Episode   151]  total reward: -486.315285476     steps:   500    q:-123.72013092, failure\n",
      "[Episode   152]  total reward: -223.263993943     steps:   500    q:-102.558189392, failure\n",
      "[Episode   153]  total reward: -76.5302240048     steps:   500    q:-121.364883423, failure\n",
      "[Episode   154]  total reward: -378.309935324     steps:   500    q:-47.1972846985, failure\n",
      "[Episode   155]  total reward: -43.4940800796     steps:   500    q:-59.1465530396, failure\n",
      "[Episode   156]  total reward: -316.092091132     steps:   500    q:-37.0476455688, failure\n",
      "[Episode   157]  total reward: -469.065345624     steps:   500    q:-4.62767982483, failure\n",
      "[Episode   158]  total reward: -436.756446529     steps:   500    q:-141.355316162, failure\n",
      "[Episode   159]  total reward: -425.026134679     steps:   500    q:-137.84765625, failure\n",
      "[Episode   160]  total reward: -272.517893167     steps:   500    q:-54.071105957, failure\n",
      "[Episode   161]  total reward: -76.435492241     steps:   500    q:6.72579669952, failure\n",
      "[Episode   162]  total reward: -8.66866430145     steps:   500    q:-95.1840438843, failure\n",
      "[Episode   163]  total reward: -67.4004688018     steps:   500    q:-46.9585456848, failure\n",
      "[Episode   164]  total reward: -269.468324659     steps:   500    q:-132.593566895, failure\n",
      "[Episode   165]  total reward: -37.4858881455     steps:   500    q:-113.619361877, failure\n",
      "[Episode   166]  total reward: -220.996400786     steps:   500    q:-81.4958343506, failure\n",
      "[Episode   167]  total reward: -117.872522018     steps:   500    q:-76.7146224976, failure\n",
      "[Episode   168]  total reward: -72.9101306645     steps:   500    q:-162.788009644, failure\n",
      "[Episode   169]  total reward: -434.442869626     steps:   500    q:-163.980621338, failure\n",
      "[Episode   170]  total reward: -332.725411064     steps:   500    q:-167.286773682, failure\n",
      "[Episode   171]  total reward: -464.753539948     steps:   500    q:-80.0130462646, failure\n",
      "[Episode   172]  total reward: -500.264784776     steps:   500    q:-112.433258057, failure\n",
      "[Episode   173]  total reward: -142.42060108     steps:   500    q:-48.294757843, failure\n",
      "[Episode   174]  total reward: -5.92663070687     steps:   500    q:-57.223739624, failure\n",
      "[Episode   175]  total reward: -97.2664400784     steps:   500    q:170.128890991, failure\n",
      "[Episode   176]  total reward: -489.15572259     steps:   500    q:-77.1926422119, failure\n",
      "[Episode   177]  total reward: -232.599464948     steps:   500    q:-129.628479004, failure\n",
      "[Episode   178]  total reward: -161.271457665     steps:   500    q:-141.957504272, failure\n",
      "[Episode   179]  total reward: -534.610710539     steps:   500    q:-112.555862427, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   180]  total reward: -320.008978081     steps:   500    q:-101.043563843, failure\n",
      "[Episode   181]  total reward: -407.962235421     steps:   500    q:-147.774368286, failure\n",
      "[Episode   182]  total reward: -522.677456628     steps:   500    q:-152.371139526, failure\n",
      "[Episode   183]  total reward: -429.538529611     steps:   500    q:-163.859313965, failure\n",
      "[Episode   184]  total reward: -550.869534409     steps:   500    q:-156.170150757, failure\n",
      "[Episode   185]  total reward: -551.464277762     steps:   500    q:-195.62840271, failure\n",
      "[Episode   186]  total reward: -366.255644196     steps:   500    q:-177.950042725, failure\n",
      "[Episode   187]  total reward: -282.054227039     steps:   500    q:-112.253753662, failure\n",
      "[Episode   188]  total reward: -567.398062353     steps:   500    q:-209.266555786, failure\n",
      "[Episode   189]  total reward: -361.959073846     steps:   500    q:-154.42755127, failure\n",
      "[Episode   190]  total reward: -318.47543107     steps:   500    q:-168.627639771, failure\n",
      "[Episode   191]  total reward: -295.646113715     steps:   500    q:-215.666732788, failure\n",
      "[Episode   192]  total reward: -485.110738246     steps:   500    q:-192.114364624, failure\n",
      "[Episode   193]  total reward: -490.018821567     steps:   500    q:-187.31187439, failure\n",
      "[Episode   194]  total reward: -507.786227749     steps:   500    q:-167.803649902, failure\n",
      "[Episode   195]  total reward: -567.102059416     steps:   500    q:-189.815795898, failure\n",
      "[Episode   196]  total reward: -487.184853299    steps:   319    q:-189.5521698, success\n",
      "[Episode   197]  total reward: -567.649208951     steps:   500    q:-142.959579468, failure\n",
      "[Episode   198]  total reward: -398.811074202     steps:   500    q:103.953689575, failure\n",
      "[Episode   199]  total reward: 155.81273308    steps:    80    q:-44.7275886536, success\n",
      "[Episode   200]  total reward: -513.673755225     steps:   500    q:-242.934310913, failure\n",
      "[Episode   201]  total reward: -338.690589692     steps:   500    q:-242.582839966, failure\n",
      "[Episode   202]  total reward: -602.903527477     steps:   500    q:-194.508239746, failure\n",
      "[Episode   203]  total reward: -476.349618914     steps:   500    q:-283.769226074, failure\n",
      "[Episode   204]  total reward: -515.09413906     steps:   500    q:-291.363677979, failure\n",
      "[Episode   205]  total reward: -501.657292362     steps:   500    q:-270.220428467, failure\n",
      "[Episode   206]  total reward: -400.108555742     steps:   500    q:-72.2207870483, failure\n",
      "[Episode   207]  total reward: -563.239987369     steps:   500    q:-271.784179688, failure\n",
      "[Episode   208]  total reward: -481.707684833     steps:   500    q:-252.836105347, failure\n",
      "[Episode   209]  total reward: -538.556899107     steps:   500    q:-250.199417114, failure\n",
      "[Episode   210]  total reward: -70.7613894615     steps:   500    q:-223.422744751, failure\n",
      "[Episode   211]  total reward: -495.181759606     steps:   500    q:-176.720703125, failure\n",
      "[Episode   212]  total reward: -214.852917507     steps:   500    q:-206.635375977, failure\n",
      "[Episode   213]  total reward: -230.921390693     steps:   500    q:-270.21472168, failure\n",
      "[Episode   214]  total reward: -288.929128196     steps:   500    q:-226.791122437, failure\n",
      "[Episode   215]  total reward: -354.311101403     steps:   500    q:-180.894226074, failure\n",
      "[Episode   216]  total reward: -232.781916016     steps:   500    q:-188.132553101, failure\n",
      "[Episode   217]  total reward: -421.814063844     steps:   500    q:-210.732696533, failure\n",
      "[Episode   218]  total reward: -190.446630884     steps:   500    q:-179.54977417, failure\n",
      "[Episode   219]  total reward: -131.227488918     steps:   500    q:-190.195846558, failure\n",
      "[Episode   220]  total reward: -316.771509604     steps:   500    q:-187.705963135, failure\n",
      "[Episode   221]  total reward: -138.421449029     steps:   500    q:-146.441650391, failure\n",
      "[Episode   222]  total reward: -194.626843715     steps:   500    q:-154.641571045, failure\n",
      "[Episode   223]  total reward: -205.204212935     steps:   500    q:-144.730407715, failure\n",
      "[Episode   224]  total reward: -231.422930585     steps:   500    q:-131.984985352, failure\n",
      "[Episode   225]  total reward: -438.678052362     steps:   500    q:-168.851211548, failure\n",
      "[Episode   226]  total reward: -413.627102366     steps:   500    q:-215.721405029, failure\n",
      "[Episode   227]  total reward: -410.751570349     steps:   500    q:-148.223495483, failure\n",
      "[Episode   228]  total reward: -313.769865284     steps:   500    q:-182.721862793, failure\n",
      "[Episode   229]  total reward: -274.215385732     steps:   500    q:-138.244613647, failure\n",
      "[Episode   230]  total reward: -449.944291267     steps:   500    q:-108.77456665, failure\n",
      "[Episode   231]  total reward: -429.279890977     steps:   500    q:-111.313690186, failure\n",
      "[Episode   232]  total reward: -319.467594995     steps:   500    q:-117.792861938, failure\n",
      "[Episode   233]  total reward: -397.508339513     steps:   500    q:-158.899490356, failure\n",
      "[Episode   234]  total reward: -359.83454031     steps:   500    q:-182.095443726, failure\n",
      "[Episode   235]  total reward: -468.186948682     steps:   500    q:-153.16784668, failure\n",
      "[Episode   236]  total reward: -231.066981809     steps:   500    q:-198.940063477, failure\n",
      "[Episode   237]  total reward: -389.032953716     steps:   500    q:-233.741333008, failure\n",
      "[Episode   238]  total reward: -580.152528203     steps:   500    q:-247.926086426, failure\n",
      "[Episode   239]  total reward: -502.813674951     steps:   500    q:-227.810928345, failure\n",
      "[Episode   240]  total reward: -341.199549229     steps:   500    q:-274.427490234, failure\n",
      "[Episode   241]  total reward: -55.4611216357     steps:   500    q:-118.508651733, failure\n",
      "[Episode   242]  total reward: -321.985800563     steps:   500    q:-197.165344238, failure\n",
      "[Episode   243]  total reward: -479.830026677     steps:   500    q:103.585174561, failure\n",
      "[Episode   244]  total reward: -122.00055169     steps:   500    q:-148.316680908, failure\n",
      "[Episode   245]  total reward: -207.823278467     steps:   500    q:-97.9704360962, failure\n",
      "[Episode   246]  total reward: -184.909374219     steps:   500    q:-70.068977356, failure\n",
      "[Episode   247]  total reward: -247.246166281     steps:   500    q:-192.739547729, failure\n",
      "[Episode   248]  total reward: -497.665863789     steps:   500    q:-137.976745605, failure\n",
      "[Episode   249]  total reward: -514.469565669     steps:   500    q:-163.477218628, failure\n",
      "[Episode   250]  total reward: -331.801208702     steps:   500    q:-31.9231491089, failure\n",
      "[Episode   251]  total reward: -206.510423355     steps:   500    q:-76.7069549561, failure\n",
      "[Episode   252]  total reward: -255.483905535     steps:   500    q:-106.610153198, failure\n",
      "[Episode   253]  total reward: -196.37845183     steps:   500    q:-99.3991088867, failure\n",
      "[Episode   254]  total reward: -361.809635028     steps:   500    q:-173.598861694, failure\n",
      "[Episode   255]  total reward: -183.026225181     steps:   500    q:-84.5990371704, failure\n",
      "[Episode   256]  total reward: -300.404737432     steps:   500    q:-111.468215942, failure\n",
      "[Episode   257]  total reward: -98.8354931185     steps:   500    q:-143.272094727, failure\n",
      "[Episode   258]  total reward: -52.9820177027    steps:   329    q:-25.0211868286, success\n",
      "[Episode   259]  total reward: -301.767618737    steps:   460    q:41.0386123657, success\n",
      "[Episode   260]  total reward: -312.59693112    steps:   157    q:246.923858643, success\n",
      "[Episode   261]  total reward: -328.160252315    steps:   152    q:-12.8493328094, success\n",
      "[Episode   262]  total reward: -256.874219655     steps:   500    q:-113.021194458, failure\n",
      "[Episode   263]  total reward: -53.2390576324    steps:    79    q:159.877120972, success\n",
      "[Episode   264]  total reward: -495.18427133     steps:   500    q:-175.059967041, failure\n",
      "[Episode   265]  total reward: 793.956606062    steps:    11    q:252.388031006, success\n",
      "[Episode   266]  total reward: 759.771537299    steps:    13    q:199.931411743, success\n",
      "[Episode   267]  total reward: 759.771537299    steps:    13    q:198.788894653, success\n",
      "[Episode   268]  total reward: -289.799684167    steps:   134    q:-25.4963951111, success\n",
      "[Episode   269]  total reward: -275.145365017     steps:   500    q:100.047531128, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   270]  total reward: 745.003636627    steps:    14    q:311.657928467, success\n",
      "[Episode   271]  total reward: 34.2780772605    steps:    88    q:201.088973999, success\n",
      "[Episode   272]  total reward: -155.557985831    steps:   294    q:-26.8141441345, success\n",
      "[Episode   273]  total reward: 701.935038554    steps:    17    q:370.459625244, success\n",
      "[Episode   274]  total reward: 643.88790836    steps:    20    q:293.881652832, success\n",
      "[Episode   275]  total reward: 759.771537299    steps:    13    q:264.90814209, success\n",
      "[Episode   276]  total reward: -264.985341956     steps:   500    q:-53.3384819031, failure\n",
      "[Episode   277]  total reward: 814.486219523    steps:    10    q:457.897705078, success\n",
      "[Episode   278]  total reward: -440.553361266    steps:   430    q:-152.910247803, success\n",
      "[Episode   279]  total reward: -426.168495641     steps:   500    q:-106.005310059, failure\n",
      "[Episode   280]  total reward: 447.778828364    steps:    31    q:394.6902771, success\n",
      "[Episode   281]  total reward: -503.118266143     steps:   500    q:-155.372909546, failure\n",
      "[Episode   282]  total reward: -284.331451235    steps:   356    q:43.7871780396, success\n",
      "[Episode   283]  total reward: -291.808888648    steps:   453    q:-108.124755859, success\n",
      "[Episode   284]  total reward: -397.450623763     steps:   500    q:-156.736190796, failure\n",
      "[Episode   285]  total reward: -318.968467877     steps:   500    q:-13.4768047333, failure\n",
      "[Episode   286]  total reward: -266.865982418     steps:   500    q:-113.500984192, failure\n",
      "[Episode   287]  total reward: -58.3059919763     steps:   500    q:-76.8251113892, failure\n",
      "[Episode   288]  total reward: -465.587589337     steps:   500    q:25.9707813263, failure\n",
      "[Episode   289]  total reward: 737.663115615    steps:    14    q:483.017791748, success\n",
      "[Episode   290]  total reward: -259.854155758     steps:   500    q:-24.9577655792, failure\n",
      "[Episode   291]  total reward: -329.820581514     steps:   500    q:-151.158065796, failure\n",
      "[Episode   292]  total reward: -289.568354939    steps:   232    q:68.3406677246, success\n",
      "[Episode   293]  total reward: -204.895209574     steps:   500    q:-183.653579712, failure\n",
      "[Episode   294]  total reward: -281.346932215     steps:   500    q:-125.284957886, failure\n",
      "[Episode   295]  total reward: -394.466754232     steps:   500    q:41.3705482483, failure\n",
      "[Episode   296]  total reward: -307.576408718     steps:   500    q:-114.49949646, failure\n",
      "[Episode   297]  total reward: -439.923543421     steps:   500    q:-128.122573853, failure\n",
      "[Episode   298]  total reward: -395.220728428     steps:   500    q:-125.141052246, failure\n",
      "[Episode   299]  total reward: 791.068099625    steps:    11    q:394.698547363, success\n",
      "[Episode   300]  total reward: 793.956606062    steps:    11    q:421.503204346, success\n",
      "[Episode   301]  total reward: 711.353142088    steps:    16    q:412.253173828, success\n",
      "[Episode   302]  total reward: 761.462927848    steps:    13    q:387.744628906, success\n",
      "[Episode   303]  total reward: 793.956606062    steps:    11    q:394.356536865, success\n",
      "[Episode   304]  total reward: 761.597826256    steps:    13    q:375.574859619, success\n",
      "[Episode   305]  total reward: 780.374020448    steps:    12    q:483.475585938, success\n",
      "[Episode   306]  total reward: -464.503420936     steps:   500    q:-97.7877349854, failure\n",
      "[Episode   307]  total reward: 798.090520758    steps:    11    q:649.161804199, success\n",
      "[Episode   308]  total reward: -212.921504153     steps:   500    q:70.707359314, failure\n",
      "[Episode   309]  total reward: 796.511305327    steps:    11    q:559.435058594, success\n",
      "[Episode   310]  total reward: 780.495657257    steps:    12    q:588.115539551, success\n",
      "[Episode   311]  total reward: 799.048684182    steps:    11    q:623.046203613, success\n",
      "[Episode   312]  total reward: 750.204591087    steps:    14    q:555.588806152, success\n",
      "[Episode   313]  total reward: 799.012888918    steps:    11    q:632.987670898, success\n",
      "[Episode   314]  total reward: 662.07631606    steps:    19    q:497.665557861, success\n",
      "[Episode   315]  total reward: 745.463736529    steps:    14    q:443.183105469, success\n",
      "[Episode   316]  total reward: 224.531904815    steps:    51    q:469.15725708, success\n",
      "[Episode   317]  total reward: -416.123927917     steps:   500    q:-11.274433136, failure\n",
      "[Episode   318]  total reward: -330.275451061     steps:   500    q:12.2829179764, failure\n",
      "[Episode   319]  total reward: -486.176002203     steps:   500    q:-62.7963294983, failure\n",
      "[Episode   320]  total reward: -318.187872461     steps:   500    q:437.750366211, failure\n",
      "[Episode   321]  total reward: -87.7808085204    steps:    94    q:113.623054504, success\n",
      "[Episode   322]  total reward: 690.577371502    steps:    18    q:788.385314941, success\n",
      "[Episode   323]  total reward: -52.2750439735    steps:    96    q:650.106811523, success\n",
      "[Episode   324]  total reward: 715.755090663    steps:    15    q:588.951477051, success\n",
      "[Episode   325]  total reward: -447.55622265    steps:   271    q:-24.228515625, success\n",
      "[Episode   326]  total reward: -285.292531736    steps:   444    q:218.116134644, success\n",
      "[Episode   327]  total reward: -452.226792032     steps:   500    q:551.580932617, failure\n",
      "[Episode   328]  total reward: 368.167316469    steps:    49    q:131.059875488, success\n",
      "[Episode   329]  total reward: -436.21686699     steps:   500    q:-104.478363037, failure\n",
      "[Episode   330]  total reward: 812.764437535    steps:    10    q:426.532531738, success\n",
      "[Episode   331]  total reward: 830.313364224    steps:     9    q:492.110626221, success\n",
      "[Episode   332]  total reward: 799.916809715    steps:    11    q:560.404052734, success\n",
      "[Episode   333]  total reward: -489.331744626     steps:   500    q:-102.963287354, failure\n",
      "[Episode   334]  total reward: 152.05300746    steps:    49    q:160.431259155, success\n",
      "[Episode   335]  total reward: -309.478439673    steps:   216    q:152.740020752, success\n",
      "[Episode   336]  total reward: -9.26838470759    steps:    70    q:356.33706665, success\n",
      "[Episode   337]  total reward: 690.308259975    steps:    18    q:557.37487793, success\n",
      "[Episode   338]  total reward: 718.888761346    steps:    16    q:549.538330078, success\n",
      "[Episode   339]  total reward: -291.077267638     steps:   500    q:396.2421875, failure\n",
      "[Episode   340]  total reward: -94.0279744435    steps:   387    q:314.233123779, success\n",
      "[Episode   341]  total reward: -328.472607763    steps:   201    q:456.288513184, success\n",
      "[Episode   342]  total reward: -187.977012593    steps:   143    q:87.9519805908, success\n",
      "[Episode   343]  total reward: 639.282627161    steps:    22    q:566.619812012, success\n",
      "[Episode   344]  total reward: -164.033236475    steps:   109    q:-5.69040727615, success\n",
      "[Episode   345]  total reward: 567.327016516    steps:    25    q:484.79006958, success\n",
      "[Episode   346]  total reward: -59.4789950055    steps:   354    q:550.697021484, success\n",
      "[Episode   347]  total reward: -204.109852105    steps:    90    q:524.031921387, success\n",
      "[Episode   348]  total reward: -480.726257471     steps:   500    q:310.779815674, failure\n",
      "[Episode   349]  total reward: 126.407514355    steps:    54    q:493.236541748, success\n",
      "[Episode   350]  total reward: -320.55860814    steps:   237    q:470.144348145, success\n",
      "[Episode   351]  total reward: 423.147750681    steps:    36    q:200.517166138, success\n",
      "[Episode   352]  total reward: 712.179588338    steps:    15    q:433.19039917, success\n",
      "[Episode   353]  total reward: 799.916809715    steps:    11    q:513.918701172, success\n",
      "[Episode   354]  total reward: -74.3991034401    steps:    79    q:452.238922119, success\n",
      "[Episode   355]  total reward: 691.226733073    steps:    18    q:274.039215088, success\n",
      "[Episode   356]  total reward: 634.965495782    steps:    22    q:522.566650391, success\n",
      "[Episode   357]  total reward: -166.834322168    steps:   248    q:420.005493164, success\n",
      "[Episode   358]  total reward: 685.846635179    steps:    18    q:554.417541504, success\n",
      "[Episode   359]  total reward: -339.662571092     steps:   500    q:377.80456543, failure\n",
      "[Episode   360]  total reward: -459.529974795     steps:   500    q:385.566192627, failure\n",
      "[Episode   361]  total reward: -420.404552942    steps:   365    q:253.454650879, success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   362]  total reward: -460.049973502     steps:   500    q:-111.42527771, failure\n",
      "[Episode   363]  total reward: -599.951678976     steps:   500    q:-32.0063819885, failure\n",
      "[Episode   364]  total reward: -310.359291577    steps:   195    q:174.060119629, success\n",
      "[Episode   365]  total reward: -123.231794551    steps:   184    q:17.9128360748, success\n",
      "[Episode   366]  total reward: -359.506917757    steps:   127    q:157.77116394, success\n",
      "[Episode   367]  total reward: -353.895650418     steps:   500    q:-126.830474854, failure\n",
      "[Episode   368]  total reward: -362.089541812     steps:   500    q:-106.32447052, failure\n",
      "[Episode   369]  total reward: -280.743415585     steps:   500    q:-93.1070785522, failure\n",
      "[Episode   370]  total reward: -376.02713769     steps:   500    q:22.1578598022, failure\n",
      "[Episode   371]  total reward: -526.23851549     steps:   500    q:57.1808433533, failure\n",
      "[Episode   372]  total reward: -143.755584835     steps:   500    q:-97.9694290161, failure\n",
      "[Episode   373]  total reward: -326.811760424     steps:   500    q:124.273033142, failure\n",
      "[Episode   374]  total reward: -162.36864232    steps:    90    q:446.33694458, success\n",
      "[Episode   375]  total reward: -307.854069441    steps:   475    q:-3.73033308983, success\n",
      "[Episode   376]  total reward: -412.034012092    steps:   309    q:85.9687347412, success\n",
      "[Episode   377]  total reward: -356.157757476    steps:   194    q:30.392375946, success\n",
      "[Episode   378]  total reward: 210.472049976    steps:    52    q:320.021820068, success\n",
      "[Episode   379]  total reward: 454.661588036    steps:    31    q:268.065612793, success\n",
      "[Episode   380]  total reward: -327.028854527    steps:   411    q:17.0850925446, success\n",
      "[Episode   381]  total reward: -226.447593166    steps:   329    q:156.605178833, success\n",
      "[Episode   382]  total reward: -268.965151767     steps:   500    q:43.8873596191, failure\n",
      "[Episode   383]  total reward: -319.664005665     steps:   500    q:57.5796051025, failure\n",
      "[Episode   384]  total reward: -386.388774708    steps:   303    q:-38.0914077759, success\n",
      "[Episode   385]  total reward: -162.875837413    steps:   436    q:21.7465648651, success\n",
      "[Episode   386]  total reward: -92.1713667452    steps:   275    q:24.2262115479, success\n",
      "[Episode   387]  total reward: 626.632171014    steps:    20    q:173.665084839, success\n",
      "[Episode   388]  total reward: -17.0486474468    steps:   202    q:171.819885254, success\n",
      "[Episode   389]  total reward: -149.375158162     steps:   500    q:-141.958984375, failure\n",
      "[Episode   390]  total reward: -184.920124198     steps:   500    q:-84.0667648315, failure\n",
      "[Episode   391]  total reward: -30.402583988     steps:   500    q:-67.0419845581, failure\n",
      "[Episode   392]  total reward: -521.493105513     steps:   500    q:-144.375839233, failure\n",
      "[Episode   393]  total reward: -16.3204654209     steps:   500    q:22.1161556244, failure\n",
      "[Episode   394]  total reward: -25.9340516699     steps:   500    q:9.66734409332, failure\n",
      "[Episode   395]  total reward: -2.94892616996     steps:   500    q:-5.00976228714, failure\n",
      "[Episode   396]  total reward: -646.516760218     steps:   500    q:45.7630653381, failure\n",
      "[Episode   397]  total reward: -286.718203887     steps:   500    q:189.009048462, failure\n",
      "[Episode   398]  total reward: -180.130598348     steps:   500    q:458.599853516, failure\n",
      "[Episode   399]  total reward: -178.716978801     steps:   500    q:277.334228516, failure\n",
      "[Episode   400]  total reward: -104.506850774    steps:   121    q:77.7586669922, success\n",
      "[Episode   401]  total reward: -310.818931715     steps:   500    q:171.004364014, failure\n",
      "[Episode   402]  total reward: -141.907370653     steps:   500    q:61.788608551, failure\n",
      "[Episode   403]  total reward: -451.773210065     steps:   500    q:25.7773742676, failure\n",
      "[Episode   404]  total reward: -234.8505747     steps:   500    q:-23.0505943298, failure\n",
      "[Episode   405]  total reward: -392.434924717     steps:   500    q:-16.430683136, failure\n",
      "[Episode   406]  total reward: -248.422404916     steps:   500    q:-54.7938842773, failure\n",
      "[Episode   407]  total reward: -533.949337204     steps:   500    q:-67.7143478394, failure\n",
      "[Episode   408]  total reward: -353.358535865     steps:   500    q:-47.1705856323, failure\n",
      "[Episode   409]  total reward: -244.67644365     steps:   500    q:-17.7442378998, failure\n",
      "[Episode   410]  total reward: -85.7364567724     steps:   500    q:-118.198318481, failure\n",
      "[Episode   411]  total reward: -320.665400657     steps:   500    q:-87.9118881226, failure\n",
      "[Episode   412]  total reward: -465.589945762     steps:   500    q:-130.783035278, failure\n",
      "[Episode   413]  total reward: -459.774719957    steps:   197    q:-44.5763244629, success\n",
      "[Episode   414]  total reward: -94.1363500197     steps:   500    q:-165.945129395, failure\n",
      "[Episode   415]  total reward: -424.347977611     steps:   500    q:-177.013778687, failure\n",
      "[Episode   416]  total reward: -349.395132778     steps:   500    q:-233.791503906, failure\n",
      "[Episode   417]  total reward: -422.183721818     steps:   500    q:-222.794296265, failure\n",
      "[Episode   418]  total reward: -460.686329653     steps:   500    q:-172.147079468, failure\n",
      "[Episode   419]  total reward: -339.054878857     steps:   500    q:-192.151733398, failure\n",
      "[Episode   420]  total reward: -639.290090051    steps:   250    q:123.34551239, success\n",
      "[Episode   421]  total reward: -629.413860308     steps:   500    q:126.846893311, failure\n",
      "[Episode   422]  total reward: -483.2809194     steps:   500    q:-172.759475708, failure\n",
      "[Episode   423]  total reward: -242.037393442    steps:   458    q:24.1888523102, success\n",
      "[Episode   424]  total reward: -541.37892644    steps:   389    q:178.414138794, success\n",
      "[Episode   425]  total reward: -571.331334941     steps:   500    q:153.809890747, failure\n",
      "[Episode   426]  total reward: -472.566591437     steps:   500    q:128.430160522, failure\n",
      "[Episode   427]  total reward: -390.394322817     steps:   500    q:-28.9199485779, failure\n",
      "[Episode   428]  total reward: -97.9476931393    steps:   370    q:-96.6889266968, success\n",
      "[Episode   429]  total reward: -146.988261027     steps:   500    q:-24.1649398804, failure\n",
      "[Episode   430]  total reward: -75.655916683     steps:   500    q:6.13753890991, failure\n",
      "[Episode   431]  total reward: -63.8876442384     steps:   500    q:83.4365921021, failure\n",
      "[Episode   432]  total reward: -43.4081791822     steps:   500    q:361.611938477, failure\n",
      "[Episode   433]  total reward: -458.717903657    steps:   447    q:241.38104248, success\n",
      "[Episode   434]  total reward: -5.07801609093     steps:   500    q:-3.89175772667, failure\n",
      "[Episode   435]  total reward: -401.540504825     steps:   500    q:146.187988281, failure\n",
      "[Episode   436]  total reward: -300.804628928     steps:   500    q:83.3320617676, failure\n",
      "[Episode   437]  total reward: -111.88765824     steps:   500    q:202.920532227, failure\n",
      "[Episode   438]  total reward: -357.434009458     steps:   500    q:34.8100738525, failure\n",
      "[Episode   439]  total reward: -456.348822766     steps:   500    q:227.61869812, failure\n",
      "[Episode   440]  total reward: -440.15341236     steps:   500    q:30.2764587402, failure\n",
      "[Episode   441]  total reward: -325.606382258     steps:   500    q:-15.8311014175, failure\n",
      "[Episode   442]  total reward: -542.051793214     steps:   500    q:-200.769165039, failure\n",
      "[Episode   443]  total reward: -488.841490883     steps:   500    q:-164.615127563, failure\n",
      "[Episode   444]  total reward: -21.7518052895     steps:   500    q:-52.774974823, failure\n",
      "[Episode   445]  total reward: -1.00117747665     steps:   500    q:-68.0532989502, failure\n",
      "[Episode   446]  total reward: -10.2585033225     steps:   500    q:-77.9201278687, failure\n",
      "[Episode   447]  total reward: -192.41426595     steps:   500    q:3.84157919884, failure\n",
      "[Episode   448]  total reward: -360.652704322     steps:   500    q:-94.6631088257, failure\n",
      "[Episode   449]  total reward: -328.525023676     steps:   500    q:-53.0531959534, failure\n",
      "[Episode   450]  total reward: -339.00174107     steps:   500    q:-1.44287502766, failure\n",
      "[Episode   451]  total reward: -121.832703622     steps:   500    q:-89.0988006592, failure\n",
      "[Episode   452]  total reward: -134.339696303     steps:   500    q:-92.821762085, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   453]  total reward: -102.167384247     steps:   500    q:-56.7544937134, failure\n",
      "[Episode   454]  total reward: -76.1150785379     steps:   500    q:-69.1335449219, failure\n",
      "[Episode   455]  total reward: -211.545991232     steps:   500    q:-77.1495437622, failure\n",
      "[Episode   456]  total reward: -399.402245038     steps:   500    q:-27.2617263794, failure\n",
      "[Episode   457]  total reward: -256.164342291     steps:   500    q:-43.0661087036, failure\n",
      "[Episode   458]  total reward: -390.886819111     steps:   500    q:-126.803688049, failure\n",
      "[Episode   459]  total reward: -440.532934348     steps:   500    q:-66.7080230713, failure\n",
      "[Episode   460]  total reward: -285.915468306     steps:   500    q:-36.9842224121, failure\n",
      "[Episode   461]  total reward: -420.754289555     steps:   500    q:-43.3149147034, failure\n",
      "[Episode   462]  total reward: -77.2404040191     steps:   500    q:46.264087677, failure\n",
      "[Episode   463]  total reward: -349.532457505     steps:   500    q:-0.123007811606, failure\n",
      "[Episode   464]  total reward: -398.651747251     steps:   500    q:-1.12299025059, failure\n",
      "[Episode   465]  total reward: -509.05944448     steps:   500    q:74.002204895, failure\n",
      "[Episode   466]  total reward: -504.135513578     steps:   500    q:-106.242362976, failure\n",
      "[Episode   467]  total reward: -631.905700188     steps:   500    q:-149.124786377, failure\n",
      "[Episode   468]  total reward: -447.852618404     steps:   500    q:-109.395965576, failure\n",
      "[Episode   469]  total reward: -349.195999683     steps:   500    q:-131.315002441, failure\n",
      "[Episode   470]  total reward: -45.1345274864     steps:   500    q:-161.282211304, failure\n",
      "[Episode   471]  total reward: -14.8723233992     steps:   500    q:-108.605262756, failure\n",
      "[Episode   472]  total reward: -82.0753993004     steps:   500    q:-92.9677276611, failure\n",
      "[Episode   473]  total reward: -3.43172691937     steps:   500    q:-110.393844604, failure\n",
      "[Episode   474]  total reward: -51.4980062358     steps:   500    q:-104.339744568, failure\n",
      "[Episode   475]  total reward: -53.1091016066     steps:   500    q:-114.365104675, failure\n",
      "[Episode   476]  total reward: -175.223918052     steps:   500    q:-119.158622742, failure\n",
      "[Episode   477]  total reward: -15.6850178767     steps:   500    q:-72.3336639404, failure\n",
      "[Episode   478]  total reward: -47.9025307202     steps:   500    q:-77.846862793, failure\n",
      "[Episode   479]  total reward: -24.8658885806    steps:   174    q:-96.1338348389, success\n",
      "[Episode   480]  total reward: -3.9956381039     steps:   500    q:-98.0892410278, failure\n",
      "[Episode   481]  total reward: -163.217760064     steps:   500    q:-114.572738647, failure\n",
      "[Episode   482]  total reward: -123.114019983     steps:   500    q:-95.0048141479, failure\n",
      "[Episode   483]  total reward: -306.863071488     steps:   500    q:-68.0466918945, failure\n",
      "[Episode   484]  total reward: -317.940945086     steps:   500    q:-86.8304824829, failure\n",
      "[Episode   485]  total reward:   0.0     steps:   500    q:-36.7786331177, failure\n",
      "[Episode   486]  total reward: -37.4935122988     steps:   500    q:-26.405670166, failure\n",
      "[Episode   487]  total reward: -50.3079567424     steps:   500    q:-58.6002693176, failure\n",
      "[Episode   488]  total reward: -11.2945447272     steps:   500    q:-67.7142868042, failure\n",
      "[Episode   489]  total reward: -41.807169134     steps:   500    q:-57.7214584351, failure\n",
      "[Episode   490]  total reward: -73.685555895     steps:   500    q:-76.9508285522, failure\n",
      "[Episode   491]  total reward: -160.000484313     steps:   500    q:-100.519737244, failure\n",
      "[Episode   492]  total reward: -275.491712991     steps:   500    q:-35.3739471436, failure\n",
      "[Episode   493]  total reward: -45.8845251968     steps:   500    q:-91.1489486694, failure\n",
      "[Episode   494]  total reward: -140.037258098     steps:   500    q:-22.7410163879, failure\n",
      "[Episode   495]  total reward: -17.985653552     steps:   500    q:-67.42603302, failure\n",
      "[Episode   496]  total reward: -34.7441622076     steps:   500    q:-31.3737564087, failure\n",
      "[Episode   497]  total reward: -18.3048481499     steps:   500    q:-62.3013420105, failure\n",
      "[Episode   498]  total reward: -154.421897306     steps:   500    q:-53.9119529724, failure\n",
      "[Episode   499]  total reward: -5.40163631328     steps:   500    q:-61.8332023621, failure\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='99b3ada5-3d6f-4dc9-a7a8-1693b113b015'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4830.51966095\n"
     ]
    }
   ],
   "source": [
    "# Plotting setting\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import dqn_cooperation\n",
    "from collections import deque\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Create New environment with transition law\n",
    "ACTION_NUM = 5\n",
    "INPUT_SIZE = 10\n",
    "OUTPUT_SIZE = ACTION_NUM**2\n",
    "VEL = 0.5\n",
    "TIME_GAP = 1\n",
    "MAP_SIZE = 7\n",
    "\n",
    "def annealing_epsilon(episode, min_e, max_e, target_episode):\n",
    "\n",
    "    slope = (min_e - max_e) / (target_episode)\n",
    "    intercept = max_e\n",
    "\n",
    "    return max(min_e, slope * episode + intercept)\n",
    "\n",
    "class new_env:     \n",
    "    def create_env(self, arg_state=[2.,3.,2.,4.], g_pos=[5.,5.], obs_pos1=[2.,2.], obs_pos2=[3.,4.], obs_size=5):\n",
    "        self.state = np.array(arg_state+g_pos+obs_pos1+obs_pos2) # reset\n",
    "        self.n_state = np.array(arg_state+g_pos+obs_pos1+obs_pos2)\n",
    "        self.obstacle_size = obs_size\n",
    "        return self.state, self.obstacle_size\n",
    "    #def add_obs(self, obs_pos), we postpone this \n",
    "    \n",
    "    def next_step(self, arg_state, arg_action):\n",
    "\n",
    "        self._fail = False\n",
    "        self.reward = 0\n",
    "        # convert to each action\n",
    "        arg_action1 = arg_action // ACTION_NUM\n",
    "        arg_action2 = arg_action - ACTION_NUM*arg_action1\n",
    "        '''position update through action\n",
    "        UP = 0, DOWN = 1, LEFT = 2, RIGHT = 3'''        \n",
    "        # agent 1\n",
    "        if arg_action1 == 0:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,1,0,0])*VEL*TIME_GAP\n",
    "        elif arg_action1 == 1:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,-1,0,0])*VEL*TIME_GAP\n",
    "        elif arg_action1 == 2:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([-1,0,0,0])*VEL*TIME_GAP\n",
    "        elif arg_action1 == 3:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([1,0,0,0])*VEL*TIME_GAP\n",
    "        else:\n",
    "            self.n_state[0:4] = arg_state[0:4] # stop        \n",
    "        # agent 2  \n",
    "        if arg_action2 == 0:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,0,0,1])*VEL*TIME_GAP\n",
    "        elif arg_action2 == 1:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,0,0,-1])*VEL*TIME_GAP\n",
    "        elif arg_action2 == 2:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,0,-1,0])*VEL*TIME_GAP\n",
    "        elif arg_action1 == 3:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,0,1,0])*VEL*TIME_GAP      \n",
    "        else:\n",
    "            self.n_state[0:4] = arg_state[0:4] # stop   \n",
    "            \n",
    "        '''get the reward'''\n",
    "        if np.linalg.norm((self.n_state[0:2]+self.n_state[2:4])/2-self.n_state[4:6])!=0:\n",
    "            self.reward = (1/np.linalg.norm((self.n_state[0:2]+self.n_state[2:4])/2-self.n_state[4:6])-\\\n",
    "            1/np.linalg.norm((arg_state[0:2]+arg_state[2:4])/2-self.n_state[4:6]))*100\n",
    "        if np.linalg.norm(self.n_state[0:2]-self.n_state[6:8])<1 or np.linalg.norm(self.n_state[2:4]-self.n_state[6:8])<1:\n",
    "            self.reward = self.reward-1 # collision\n",
    "        if np.linalg.norm(self.n_state[0:2]-self.n_state[8:10])<1 or np.linalg.norm(self.n_state[2:4]-self.n_state[8:10])<1:\n",
    "            self.reward = self.reward-1 # collision\n",
    "        if np.linalg.norm((self.n_state[0:2]+self.n_state[2:4])/2-self.n_state[4:6])<1 and np.linalg.norm(self.n_state[0:2]-self.n_state[2:4])<3: # approximately set condition\n",
    "            self.reward = self.reward + 1000 # achieve goal\n",
    "            self._fail = True\n",
    "        if np.linalg.norm(self.n_state[0:2]-self.n_state[2:4])>2.5:\n",
    "            self.reward = self.reward-np.linalg.norm(self.n_state[0:2]-self.n_state[2:4])*2 # drop the object\n",
    "            #self._fail = True     \n",
    "        return self.n_state, self.reward, self._fail\n",
    "    \n",
    "#env = new_env() \n",
    "#state, g_pos, o_pos, o_size = env.create_env() # set the enviornment\n",
    "DISCOUNT_RATE = 0.98\n",
    "REPLAY_MEMORY = 10000\n",
    "BATCH_SIZE = 50\n",
    "MAX_EPI = 500\n",
    "MAX_STEP = 500\n",
    "\n",
    "# minimum epsilon for epsilon greedy\n",
    "MIN_E = 0.1\n",
    "# epsilon will be `MIN_E` at `EPSILON_DECAYING_STEP`\n",
    "EPSILON_DECAYING_EPI = MAX_EPI * 0.2\n",
    "TARGET_UPDATE_FQ = 100\n",
    "\n",
    "def train_minibatch(mainDQN, targetDQN, minibatch):\n",
    "    state_array = np.array([x[0] for x in minibatch])\n",
    "    action_array = np.array([x[1] for x in minibatch]) # [ x among 0~24] * BATCH_SIZE\n",
    "    reward_array = np.array([x[2] for x in minibatch])\n",
    "    n_state_array = np.array([x[3] for x in minibatch]) # [[1,2,3,4][1,2,3,4]...as much as BATCH_SIZE NUMBER]\n",
    "    _fail_array = np.array([x[4] for x in minibatch])\n",
    "    \n",
    "    \n",
    "    X_batch = state_array   \n",
    "    Y_batch = mainDQN.predict(state_array) # 25 elements * BATCH_SIZE \n",
    "    \n",
    "    # consideration for action constraint \n",
    "    target_q = targetDQN.predict(n_state_array) # [[1 ...25][1...25]...batch_size]\n",
    "    j = 0\n",
    "    for x in n_state_array:        \n",
    "        t_dqn = targetDQN.predict(x) #[[1 2 3 ...]]\n",
    "        t_dqn = t_dqn.flatten() # [1 2 3 ...]\n",
    "        if x[0]<TIME_GAP*VEL:\n",
    "            for i in range(ACTION_NUM):\n",
    "                t_dqn[2*ACTION_NUM+i] = -float(\"inf\") # put a large num on action 2(left)\n",
    "        if x[1]<TIME_GAP*VEL:\n",
    "            for i in range(ACTION_NUM):\n",
    "                t_dqn[1*ACTION_NUM+i] = -float(\"inf\") # put a large num on action 1(down)\n",
    "        if x[0] > MAP_SIZE - TIME_GAP*VEL:\n",
    "            for i in range(ACTION_NUM):\n",
    "                t_dqn[3*ACTION_NUM+i] = -float(\"inf\") # remove action 3(right)\n",
    "        if x[1] > MAP_SIZE - TIME_GAP*VEL:\n",
    "            for i in range(ACTION_NUM):\n",
    "                t_dqn[0*ACTION_NUM+i] = -float(\"inf\") # remove action 0(up)  \n",
    "        if x[2]<TIME_GAP*VEL:\n",
    "            for i in range(ACTION_NUM):\n",
    "                t_dqn[i*ACTION_NUM+2] = -float(\"inf\")# put a large num on action 2(left)\n",
    "        if x[3]<TIME_GAP*VEL:\n",
    "            for i in range(ACTION_NUM):\n",
    "                t_dqn[i*ACTION_NUM+1] = -float(\"inf\") # put a large num on action 1(down)\n",
    "        if x[2] > MAP_SIZE - TIME_GAP*VEL:\n",
    "            for i in range(ACTION_NUM):\n",
    "                t_dqn[i*ACTION_NUM+3] = -float(\"inf\")# remove action 3(right)\n",
    "        if x[3] > MAP_SIZE - TIME_GAP*VEL:\n",
    "            for i in range(ACTION_NUM):\n",
    "                t_dqn[i*ACTION_NUM+0] = -float(\"inf\") # remove action 0(up)    \n",
    "        target_q[j] = t_dqn\n",
    "        j += 1\n",
    "        \n",
    "    Q_target = reward_array + DISCOUNT_RATE*np.max(target_q, axis=1)*~_fail_array # if fail, Q = reward\n",
    "    \n",
    "    Y_batch[np.arange(len(X_batch)), action_array] = Q_target\n",
    "    \n",
    "    # Train\n",
    "    cost_batch, _ = mainDQN.update(X_batch, Y_batch)\n",
    "    return cost_batch\n",
    "\n",
    "def get_copy_var_ops(dest_scope_name = \"target\", src_scope_name = \"main\"):\n",
    "    op_holder = []\n",
    "    \n",
    "    src_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=src_scope_name)\n",
    "    dest_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=dest_scope_name)\n",
    "\n",
    "    for src_var, dest_var in zip(src_vars, dest_vars):\n",
    "        op_holder.append(dest_var.assign(src_var.value()))\n",
    "\n",
    "    return op_holder\n",
    "\n",
    "\n",
    "def main():\n",
    "    replay_buffer = deque(maxlen=REPLAY_MEMORY) # detract element from both sides    \n",
    "    total_reward_buffer = []\n",
    "    step_buffer = []\n",
    "    avg_q_value = []\n",
    "    new_graph = tf.Graph()\n",
    "    with tf.Session(graph=new_graph) as sess:\n",
    "        mainDQN = dqn_cooperation.DQN(sess, INPUT_SIZE, OUTPUT_SIZE, name = \"main\")\n",
    "        mainDQN.build_network(32,64,0.005)\n",
    "        targetDQN = dqn_cooperation.DQN(sess, INPUT_SIZE, OUTPUT_SIZE, name = \"target\")\n",
    "        targetDQN.build_network(32,64,0.005)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        #restore model\n",
    "        \n",
    "        new_saver = tf.train.import_meta_graph(\"./dqn_multi_reward_easy_500.ckpt.meta\")        \n",
    "        new_saver.restore(sess,\"./dqn_multi_reward_easy_500.ckpt\")\n",
    "        \n",
    "        # initial copy main q -> target q\n",
    "        copy_ops = get_copy_var_ops(dest_scope_name = \"target\", src_scope_name = \"main\")\n",
    "        sess.run(copy_ops)\n",
    "        \n",
    "        reward_accum_last100 = 0\n",
    "        reward_sum = 0\n",
    "        \n",
    "        game = ENV(MAP_SIZE, [2,2], [3,4], [2.,3.,2.,4.], [5,5])\n",
    "        game.render_env()\n",
    "        \n",
    "        for episode in range(MAX_EPI):\n",
    "            \n",
    "            '''\n",
    "            if episode < 100:\n",
    "                e = 0.3\n",
    "            e = 0.05\n",
    "            '''\n",
    "            _fail = False\n",
    "            step_count = 0 # how many moves included in an episode\n",
    "            env1 = new_env()\n",
    "            state, _= env1.create_env() # get only state            \n",
    "            reward_sum = 0      \n",
    "            goal_ = True\n",
    "            max_qlist = []\n",
    "            while not _fail:\n",
    "                e = annealing_epsilon(episode, MIN_E, 1.0, EPSILON_DECAYING_EPI)\n",
    "                # after sufficient learning, we present the game scene\n",
    "                if episode > MAX_EPI:\n",
    "                    game.update(state)\n",
    "                    game.render_env()\n",
    "                    \n",
    "                step_count += 1\n",
    "                if np.random.rand()< e:\n",
    "                    act_candi1 = range(ACTION_NUM)\n",
    "                    act_candi2 = range(ACTION_NUM)\n",
    "                    if state[0]<TIME_GAP*VEL:\n",
    "                        act_candi1.remove(2) # remove action 2(left)\n",
    "                    if state[1]<TIME_GAP*VEL:\n",
    "                        act_candi1.remove(1) # remove action 1(down)\n",
    "                    if state[0] > MAP_SIZE - TIME_GAP*VEL:\n",
    "                        act_candi1.remove(3) # remove action 3(right)\n",
    "                    if state[1] > MAP_SIZE - TIME_GAP*VEL:\n",
    "                        act_candi1.remove(0) # remove action 0(up)    \n",
    "                    if state[2]<TIME_GAP*VEL:\n",
    "                        act_candi2.remove(2) # remove action 2(left)\n",
    "                    if state[3]<TIME_GAP*VEL:\n",
    "                        act_candi2.remove(1) # remove action 1(down)\n",
    "                    if state[2] > MAP_SIZE - TIME_GAP*VEL:\n",
    "                        act_candi2.remove(3) # remove action 3(right)\n",
    "                    if state[3] > MAP_SIZE - TIME_GAP*VEL:\n",
    "                        act_candi2.remove(0) # remove action 0(up)    \n",
    "                    act_candi1_ = np.array(act_candi1)\n",
    "                    act_candi2_ = np.array(act_candi2)\n",
    "\n",
    "                    action_l1 = random.sample(act_candi1, 1) # choose up, down, left, right, stop for agent 1\n",
    "                    action_l2 = random.sample(act_candi2, 1) # for agent 2\n",
    "                    action = action_l1[0]*(ACTION_NUM) + action_l2[0] # convert to index\n",
    "                else:\n",
    "                    act_candi = mainDQN.predict(state) # [[1 2 3 ... as much as OUTPUT_SIZE]]\n",
    "                    act_candi = act_candi.flatten()\n",
    "\n",
    "                    if state[0]<TIME_GAP*VEL:\n",
    "                        for i in range(ACTION_NUM):\n",
    "                            act_candi[2*ACTION_NUM+i] = -float(\"inf\") # put a large num on action 2(left)\n",
    "                    if state[1]<TIME_GAP*VEL:\n",
    "                        for i in range(ACTION_NUM):\n",
    "                            act_candi[1*ACTION_NUM+i] = -float(\"inf\") # put a large num on action 1(down)\n",
    "                    if state[0] > MAP_SIZE - TIME_GAP*VEL:\n",
    "                        for i in range(ACTION_NUM):\n",
    "                            act_candi[3*ACTION_NUM+i] = -float(\"inf\") # remove action 3(right)\n",
    "                    if state[1] > MAP_SIZE - TIME_GAP*VEL:\n",
    "                        for i in range(ACTION_NUM):\n",
    "                            act_candi[0*ACTION_NUM+i] = -float(\"inf\") # remove action 0(up)  \n",
    "                    if state[2]<TIME_GAP*VEL:\n",
    "                        for i in range(ACTION_NUM):\n",
    "                            act_candi[i*ACTION_NUM+2] = -float(\"inf\")# put a large num on action 2(left)\n",
    "                    if state[3]<TIME_GAP*VEL:\n",
    "                        for i in range(ACTION_NUM):\n",
    "                            act_candi[i*ACTION_NUM+1] = -float(\"inf\") # put a large num on action 1(down)\n",
    "                    if state[2] > MAP_SIZE - TIME_GAP*VEL:\n",
    "                        for i in range(ACTION_NUM):\n",
    "                            act_candi[i*ACTION_NUM+3] = -float(\"inf\")# remove action 3(right)\n",
    "                    if state[3] > MAP_SIZE - TIME_GAP*VEL:\n",
    "                        for i in range(ACTION_NUM):\n",
    "                            act_candi[i*ACTION_NUM+0] = -float(\"inf\") # remove action 0(up)    \n",
    "\n",
    "                    action = np.argmax(act_candi)   \n",
    "                    '''\n",
    "                    dd_predict = mainDQN.predict(state).flatten()\n",
    "                    aa = np.max(dd_predict)\n",
    "                    max_indx, = np.where(dd_predict==aa)                    \n",
    "                    action = random.sample(max_indx,1)[0]\n",
    "                    '''\n",
    "                \n",
    "                n_state, reward, _fail = env1.next_step(state, action) # have to input the action \n",
    "                # if count >30, stop that episode and start new episode\n",
    "                if step_count >MAX_STEP-1:\n",
    "                    #reward = -30\n",
    "                    _fail = True\n",
    "                    goal_ = False\n",
    "                    \n",
    "                reward_sum += DISCOUNT_RATE**step_count * reward    # sum total reward and penalty about long time(-0.5)     \n",
    "                \n",
    "                replay_buffer.append((state, action, reward, n_state, _fail)) #resolve the correlation                \n",
    "                if _fail == True and goal_ == True:\n",
    "                    success_tuple = (state, action, reward, n_state, _fail)\n",
    "                state = n_state\n",
    "                \n",
    "                q_values = mainDQN.predict(state) # [[1 2 3 ... as much as OUTPUT_SIZE]]\n",
    "                q_values = q_values.flatten()\n",
    "                max_q = np.max(np.array(q_values))\n",
    "                max_qlist.append(max_q)\n",
    "                # train minibatch of main Q-NET and update the  Q-network from main Q-NET\n",
    "                if len(replay_buffer)>BATCH_SIZE*3:\n",
    "                    minibatch = random.sample(replay_buffer, BATCH_SIZE) \n",
    "                    train_minibatch(mainDQN, targetDQN, minibatch) # training number = step number\n",
    "                if step_count % TARGET_UPDATE_FQ == 0:\n",
    "                    sess.run(copy_ops)\n",
    "            \n",
    "            avg_q_value.append(np.mean(max_qlist))\n",
    "            total_reward_buffer.append(reward_sum)  \n",
    "            step_buffer.append(step_count)\n",
    "            if goal_ == True:       \n",
    "                print(\"[Episode {:>5}]  total reward: {:>5}    steps: {:>5}    q:{:>5}, success\".format(episode, reward_sum, step_count, np.mean(max_qlist)))\n",
    "            else:\n",
    "                print(\"[Episode {:>5}]  total reward: {:>5}     steps: {:>5}    q:{:>5}, failure\".format(episode, reward_sum, step_count, np.mean(max_qlist)))\n",
    "        #print(\"Success ratio: {}\".format(reward_accum_last100/100))\n",
    "        fig1 =plt.figure()\n",
    "        plt.plot(range(MAX_EPI), total_reward_buffer)\n",
    "        plt.show()\n",
    "        \n",
    "        # save model  \n",
    "        #new_saver = tf.train.Saver()\n",
    "        save_path = new_saver.save(sess, \"./dqn_multi_reward_moderate_500.ckpt\")   \n",
    "        # save data (reward, step)\n",
    "        f = open(\"multi_reward_moderate_500.txt\", 'w')\n",
    "        for i in range(len(total_reward_buffer)):\n",
    "            f.write(\"{:>5}  {:>5}  {:>5}\\n\".format(total_reward_buffer[i], step_buffer[i], avg_q_value[i]))\n",
    "        f.close\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()    \n",
    "    end = time.time()-start\n",
    "    print(end)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-3-0faa2b419ff3>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-0faa2b419ff3>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    plt.show()\u001b[0m\n\u001b[0m              \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# two plot (reward, step)\n",
    "\n",
    "file = open('multi_reward_easy_500.txt', 'r')    # hello.txt íŒŒì¼ì„ ì½ê¸° ëª¨ë“œ(r)ë¡œ ì—´ê¸°. íŒŒì¼ ê°ì²´ ë°˜í™˜\n",
    "s = file.read().split( )                  # íŒŒì¼ì—ì„œ ë¬¸ìžì—´ ì½ê¸°\n",
    "reward = []\n",
    "step = []\n",
    "q = []\n",
    "for i in range(0,len(s),3):\n",
    "    reward.append(float(s[i]))\n",
    "    step.append(int(s[i+1]))\n",
    "    q.append(float(s[i+2]))\n",
    "                         # Hello, world!\n",
    "file.close()                     # íŒŒì¼ ê°ì²´ ë‹«ê¸°\n",
    "\n",
    "fig1 =plt.figure()\n",
    "plt.plot(range(len(reward)),reward, lw =0.6)\n",
    "fig2 =plt.figure()\n",
    "plt.plot(range(len(step)),step, lw=0.3)\n",
    "fig3 =plt.figure()\n",
    "plt.plot(range(len(q)),q, lw=0.6)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
