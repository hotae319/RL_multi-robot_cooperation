{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "\n",
    "class ENV:\n",
    "    def __init__(self, map_size, obs_pos1, obs_pos2, robot_start_pos, goal_pos):\n",
    "        self.map_size = map_size # integer\n",
    "        self.obs_pos1 = obs_pos1 # [a,b], 2by1 list\n",
    "        self.obs_pos2 = obs_pos2 # [a,b], 2by1 list\n",
    "        self.goal_pos = goal_pos\n",
    "        self.robot_pos1 = robot_start_pos[0:2] #[a,b] 2by1 list\n",
    "        self.robot_pos2 = robot_start_pos[2:4]\n",
    "        # set the walls\n",
    "        self.fig = plt.figure()\n",
    "        ax = plt.axes(xlim=(-0.5,self.map_size), ylim=(-0.5,self.map_size))  \n",
    "        #self.render_env()\n",
    "    def render_env(self):        \n",
    "        # draw the obstacles and goal\n",
    "        obs1 = plt.scatter(self.obs_pos1[0], self.obs_pos1[1], c='r', marker = 's', linewidths = 5) # have to check whether we can receive <list or np.array>        \n",
    "        obs2 = plt.scatter(self.obs_pos2[0], self.obs_pos2[1], c='r', marker = 's', linewidths = 5)\n",
    "        goal = plt.scatter(self.goal_pos[0], self.goal_pos[1], c='g', marker='x', linewidths = 4)\n",
    "        # draw the robot                \n",
    "        ro1 = plt.scatter(self.robot_pos1[0], self.robot_pos1[1], c='b', linewidths = 3)\n",
    "        ro2 = plt.scatter(self.robot_pos2[0], self.robot_pos2[1], c='b', linewidths = 3)        \n",
    "        self.fig.canvas.draw()   \n",
    "        sleep(0.2)\n",
    "        ro1.remove()\n",
    "        ro2.remove()        \n",
    "    def update(self, robot_current_pos):\n",
    "        self.robot_pos1 = robot_current_pos[0:2]\n",
    "        self.robot_pos2 = robot_current_pos[2:4]        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode     0]  total reward: -55214.0     steps:  3000, failure\n",
      "[Episode     1]  total reward: -51734.0     steps:  3000, failure\n",
      "[Episode     2]  total reward: -60483.0     steps:  3000, failure\n",
      "[Episode     3]  total reward: -50787.9191525     steps:  3000, failure\n",
      "[Episode     4]  total reward: -59199.0     steps:  3000, failure\n",
      "[Episode     5]  total reward: -56296.0     steps:  3000, failure\n",
      "[Episode     6]  total reward: -63469.4105692     steps:  3000, failure\n",
      "[Episode     7]  total reward: -62842.4105692     steps:  3000, failure\n",
      "[Episode     8]  total reward: -49098.0     steps:  3000, failure\n",
      "[Episode     9]  total reward: -59281.4105692     steps:  3000, failure\n",
      "[Episode    10]  total reward: -52671.0     steps:  3000, failure\n",
      "[Episode    11]  total reward: -40802.0     steps:  3000, failure\n",
      "[Episode    12]  total reward: -53797.9191525     steps:  3000, failure\n",
      "[Episode    13]  total reward: -58934.0     steps:  3000, failure\n",
      "[Episode    14]  total reward: -64894.9191525     steps:  3000, failure\n",
      "[Episode    15]  total reward: -59946.4105692     steps:  3000, failure\n",
      "[Episode    16]  total reward: -63530.0     steps:  3000, failure\n",
      "[Episode    17]  total reward: -61600.5989095     steps:  3000, failure\n",
      "[Episode    18]  total reward: -57596.9191525     steps:  3000, failure\n",
      "[Episode    19]  total reward: -64197.4105692     steps:  3000, failure\n",
      "[Episode    20]  total reward: -62895.0     steps:  3000, failure\n",
      "[Episode    21]  total reward: -63368.5989095     steps:  3000, failure\n",
      "[Episode    22]  total reward: -63683.0     steps:  3000, failure\n",
      "[Episode    23]  total reward: -52874.4105692     steps:  3000, failure\n",
      "[Episode    24]  total reward: -40240.9191525     steps:  3000, failure\n",
      "[Episode    25]  total reward: -64294.0     steps:  3000, failure\n",
      "[Episode    26]  total reward: -63155.0     steps:  3000, failure\n",
      "[Episode    27]  total reward: -64493.0     steps:  3000, failure\n",
      "[Episode    28]  total reward: -54967.4105692     steps:  3000, failure\n",
      "[Episode    29]  total reward: -41484.9191525     steps:  3000, failure\n",
      "[Episode    30]  total reward: -50674.0     steps:  3000, failure\n",
      "[Episode    31]  total reward: -64926.4105692     steps:  3000, failure\n",
      "[Episode    32]  total reward: -59178.4105692     steps:  3000, failure\n",
      "[Episode    33]  total reward: -65317.0     steps:  3000, failure\n",
      "[Episode    34]  total reward: -61054.0     steps:  3000, failure\n",
      "[Episode    35]  total reward: -63406.5989095     steps:  3000, failure\n",
      "[Episode    36]  total reward: -61382.5989095     steps:  3000, failure\n",
      "[Episode    37]  total reward: -50297.5989095     steps:  3000, failure\n",
      "[Episode    38]  total reward: -41967.4105692     steps:  3000, failure\n",
      "[Episode    39]  total reward: -61479.0     steps:  3000, failure\n",
      "[Episode    40]  total reward: -45335.9191525     steps:  3000, failure\n",
      "[Episode    41]  total reward: -64542.9191525     steps:  3000, failure\n",
      "[Episode    42]  total reward: -61120.9191525     steps:  3000, failure\n",
      "[Episode    43]  total reward: -56925.0     steps:  3000, failure\n",
      "[Episode    44]  total reward: -61863.0     steps:  3000, failure\n",
      "[Episode    45]  total reward: -65094.4105692     steps:  3000, failure\n",
      "[Episode    46]  total reward: -64588.5989095     steps:  3000, failure\n",
      "[Episode    47]  total reward: -64301.4105692     steps:  3000, failure\n",
      "[Episode    48]  total reward: -39675.4105692     steps:  3000, failure\n",
      "[Episode    49]  total reward: -60545.4105692     steps:  3000, failure\n",
      "[Episode    50]  total reward: -46863.4105692     steps:  3000, failure\n",
      "[Episode    51]  total reward: -63053.0     steps:  3000, failure\n",
      "[Episode    52]  total reward: -60829.0119498     steps:  3000, failure\n",
      "[Episode    53]  total reward: -64409.5989095     steps:  3000, failure\n",
      "[Episode    54]  total reward: -64223.0     steps:  3000, failure\n",
      "[Episode    55]  total reward: -65267.0119498     steps:  3000, failure\n",
      "[Episode    56]  total reward: -36801.0     steps:  3000, failure\n",
      "[Episode    57]  total reward: -58488.0     steps:  3000, failure\n",
      "[Episode    58]  total reward: -35929.4105692     steps:  3000, failure\n",
      "[Episode    59]  total reward: -43710.0     steps:  3000, failure\n",
      "[Episode    60]  total reward: -46105.0     steps:  3000, failure\n",
      "[Episode    61]  total reward: -64663.4105692     steps:  3000, failure\n",
      "[Episode    62]  total reward: -64310.5989095     steps:  3000, failure\n",
      "[Episode    63]  total reward: -64603.4105692     steps:  3000, failure\n",
      "[Episode    64]  total reward: -48626.4105692     steps:  3000, failure\n",
      "[Episode    65]  total reward: -38430.5989095     steps:  3000, failure\n",
      "[Episode    66]  total reward: -61493.0     steps:  3000, failure\n",
      "[Episode    67]  total reward: -44020.0     steps:  3000, failure\n",
      "[Episode    68]  total reward: -65130.9191525     steps:  3000, failure\n",
      "[Episode    69]  total reward: -44816.0     steps:  3000, failure\n",
      "[Episode    70]  total reward: -59953.0119498     steps:  3000, failure\n",
      "[Episode    71]  total reward: -38961.9191525     steps:  3000, failure\n",
      "[Episode    72]  total reward: -49128.0     steps:  3000, failure\n",
      "[Episode    73]  total reward: -43997.9191525     steps:  3000, failure\n",
      "[Episode    74]  total reward: -64722.4105692     steps:  3000, failure\n",
      "[Episode    75]  total reward: -64149.5989095     steps:  3000, failure\n",
      "[Episode    76]  total reward: -54689.5989095     steps:  3000, failure\n",
      "[Episode    77]  total reward: -63814.0     steps:  3000, failure\n",
      "[Episode    78]  total reward: -62840.0     steps:  3000, failure\n",
      "[Episode    79]  total reward: -63568.0119498     steps:  3000, failure\n",
      "[Episode    80]  total reward: -63878.5989095     steps:  3000, failure\n",
      "[Episode    81]  total reward: -64367.5989095     steps:  3000, failure\n",
      "[Episode    82]  total reward: -62601.0     steps:  3000, failure\n",
      "[Episode    83]  total reward: -58463.0     steps:  3000, failure\n",
      "[Episode    84]  total reward: -49288.0     steps:  3000, failure\n",
      "[Episode    85]  total reward: -54497.4105692     steps:  3000, failure\n",
      "[Episode    86]  total reward: -65106.9191525     steps:  3000, failure\n",
      "[Episode    87]  total reward: -61857.5989095     steps:  3000, failure\n",
      "[Episode    88]  total reward: -62373.0     steps:  3000, failure\n",
      "[Episode    89]  total reward: -64561.0     steps:  3000, failure\n",
      "[Episode    90]  total reward: -60873.5989095     steps:  3000, failure\n",
      "[Episode    91]  total reward: -54243.5989095     steps:  3000, failure\n",
      "[Episode    92]  total reward: -44218.9191525     steps:  3000, failure\n",
      "[Episode    93]  total reward: -37840.5989095     steps:  3000, failure\n",
      "[Episode    94]  total reward: -35926.9191525     steps:  3000, failure\n",
      "[Episode    95]  total reward: -37038.5989095     steps:  3000, failure\n",
      "[Episode    96]  total reward: -58431.5989095     steps:  3000, failure\n",
      "[Episode    97]  total reward: -35734.0     steps:  3000, failure\n",
      "[Episode    98]  total reward: -35779.0     steps:  3000, failure\n",
      "[Episode    99]  total reward: -50380.0     steps:  3000, failure\n",
      "[Episode   100]  total reward: -59803.9191525     steps:  3000, failure\n",
      "[Episode   101]  total reward: -49063.4105692     steps:  3000, failure\n",
      "[Episode   102]  total reward: -48691.4105692     steps:  3000, failure\n",
      "[Episode   103]  total reward: -35648.0     steps:  3000, failure\n",
      "[Episode   104]  total reward: -41311.9191525     steps:  3000, failure\n",
      "[Episode   105]  total reward: -56234.9191525     steps:  3000, failure\n",
      "[Episode   106]  total reward: -54541.0     steps:  3000, failure\n",
      "[Episode   107]  total reward: -62533.4105692     steps:  3000, failure\n",
      "[Episode   108]  total reward: -58568.5989095     steps:  3000, failure\n",
      "[Episode   109]  total reward: -54169.9191525     steps:  3000, failure\n",
      "[Episode   110]  total reward: -54427.0     steps:  3000, failure\n",
      "[Episode   111]  total reward: -48198.9191525     steps:  3000, failure\n",
      "[Episode   112]  total reward: -35791.5989095     steps:  3000, failure\n",
      "[Episode   113]  total reward: -41511.0     steps:  3000, failure\n",
      "[Episode   114]  total reward: -44857.4105692     steps:  3000, failure\n",
      "[Episode   115]  total reward: -49087.5989095     steps:  3000, failure\n",
      "[Episode   116]  total reward: -64502.5989095     steps:  3000, failure\n",
      "[Episode   117]  total reward: -54590.0     steps:  3000, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   118]  total reward: -63323.9191525     steps:  3000, failure\n",
      "[Episode   119]  total reward: -43824.9191525     steps:  3000, failure\n",
      "[Episode   120]  total reward: -50534.9191525     steps:  3000, failure\n",
      "[Episode   121]  total reward: -5738.0    steps:   430, success\n",
      "[Episode   122]  total reward: -62550.5989095     steps:  3000, failure\n",
      "[Episode   123]  total reward: -64573.4105692     steps:  3000, failure\n",
      "[Episode   124]  total reward: -37661.5989095     steps:  3000, failure\n",
      "[Episode   125]  total reward: -54633.0     steps:  3000, failure\n",
      "[Episode   126]  total reward: -40446.9191525     steps:  3000, failure\n",
      "[Episode   127]  total reward: -37747.9191525     steps:  3000, failure\n",
      "[Episode   128]  total reward: -62963.9191525     steps:  3000, failure\n",
      "[Episode   129]  total reward: -65069.5989095     steps:  3000, failure\n",
      "[Episode   130]  total reward: -60589.9191525     steps:  3000, failure\n",
      "[Episode   131]  total reward: -53906.5989095     steps:  3000, failure\n",
      "[Episode   132]  total reward: -40868.0     steps:  3000, failure\n",
      "[Episode   133]  total reward: -60000.5989095     steps:  3000, failure\n",
      "[Episode   134]  total reward: -63516.4105692     steps:  3000, failure\n",
      "[Episode   135]  total reward: -36458.0     steps:  3000, failure\n",
      "[Episode   136]  total reward: -51511.4105692     steps:  3000, failure\n",
      "[Episode   137]  total reward: -54292.0     steps:  3000, failure\n",
      "[Episode   138]  total reward: -49254.4105692     steps:  3000, failure\n",
      "[Episode   139]  total reward: -62076.5989095     steps:  3000, failure\n",
      "[Episode   140]  total reward: -44252.9191525     steps:  3000, failure\n",
      "[Episode   141]  total reward: -57341.5989095     steps:  3000, failure\n",
      "[Episode   142]  total reward: -65151.9191525     steps:  3000, failure\n",
      "[Episode   143]  total reward: -52389.0119498     steps:  3000, failure\n",
      "[Episode   144]  total reward: -35763.4105692     steps:  3000, failure\n",
      "[Episode   145]  total reward: -38400.0     steps:  3000, failure\n",
      "[Episode   146]  total reward: -60641.5989095     steps:  3000, failure\n",
      "[Episode   147]  total reward: -62283.4105692     steps:  3000, failure\n",
      "[Episode   148]  total reward: -64488.0     steps:  3000, failure\n",
      "[Episode   149]  total reward: -64945.9191525     steps:  3000, failure\n",
      "[Episode   150]  total reward: -62015.9191525     steps:  3000, failure\n",
      "[Episode   151]  total reward: -62495.4105692     steps:  3000, failure\n",
      "[Episode   152]  total reward: -59010.0     steps:  3000, failure\n",
      "[Episode   153]  total reward: -40107.4105692     steps:  3000, failure\n",
      "[Episode   154]  total reward: -49392.0     steps:  3000, failure\n",
      "[Episode   155]  total reward: -60329.0     steps:  3000, failure\n",
      "[Episode   156]  total reward: -44254.9191525     steps:  3000, failure\n",
      "[Episode   157]  total reward: -63284.0     steps:  3000, failure\n",
      "[Episode   158]  total reward: -44474.0     steps:  3000, failure\n",
      "[Episode   159]  total reward: -40217.9191525     steps:  3000, failure\n",
      "[Episode   160]  total reward: -35946.9191525     steps:  3000, failure\n",
      "[Episode   161]  total reward: -57590.0119498     steps:  3000, failure\n",
      "[Episode   162]  total reward: -54331.0     steps:  3000, failure\n",
      "[Episode   163]  total reward: -59314.5989095     steps:  3000, failure\n",
      "[Episode   164]  total reward: -64922.5989095     steps:  3000, failure\n",
      "[Episode   165]  total reward: -60240.0     steps:  3000, failure\n",
      "[Episode   166]  total reward: -65230.9191525     steps:  3000, failure\n",
      "[Episode   167]  total reward: -61294.4105692     steps:  3000, failure\n",
      "[Episode   168]  total reward: -64979.0     steps:  3000, failure\n",
      "[Episode   169]  total reward: -47178.0     steps:  3000, failure\n",
      "[Episode   170]  total reward: -63420.0     steps:  3000, failure\n",
      "[Episode   171]  total reward: -43965.4105692     steps:  3000, failure\n",
      "[Episode   172]  total reward: -49183.0     steps:  3000, failure\n",
      "[Episode   173]  total reward: -38221.0     steps:  3000, failure\n",
      "[Episode   174]  total reward: -60799.0     steps:  3000, failure\n",
      "[Episode   175]  total reward: -35793.5989095     steps:  3000, failure\n",
      "[Episode   176]  total reward: -59802.9191525     steps:  3000, failure\n",
      "[Episode   177]  total reward: -42870.5989095     steps:  3000, failure\n",
      "[Episode   178]  total reward: -60202.0119498     steps:  3000, failure\n",
      "[Episode   179]  total reward: -63507.0119498     steps:  3000, failure\n",
      "[Episode   180]  total reward: -57746.4105692     steps:  3000, failure\n",
      "[Episode   181]  total reward: -65319.0     steps:  3000, failure\n",
      "[Episode   182]  total reward: -64521.0     steps:  3000, failure\n",
      "[Episode   183]  total reward: -63712.0119498     steps:  3000, failure\n",
      "[Episode   184]  total reward: -56583.4105692     steps:  3000, failure\n",
      "[Episode   185]  total reward: -60196.5989095     steps:  3000, failure\n",
      "[Episode   186]  total reward: -60728.4105692     steps:  3000, failure\n",
      "[Episode   187]  total reward: -62459.0     steps:  3000, failure\n",
      "[Episode   188]  total reward: -36739.9191525     steps:  3000, failure\n",
      "[Episode   189]  total reward: -46697.9191525     steps:  3000, failure\n",
      "[Episode   190]  total reward: -62817.5989095     steps:  3000, failure\n",
      "[Episode   191]  total reward: -63398.9191525     steps:  3000, failure\n",
      "[Episode   192]  total reward: -59696.5989095     steps:  3000, failure\n",
      "[Episode   193]  total reward: -53547.9191525     steps:  3000, failure\n",
      "[Episode   194]  total reward: -43822.0     steps:  3000, failure\n",
      "[Episode   195]  total reward: -60409.9191525     steps:  3000, failure\n",
      "[Episode   196]  total reward: -38641.0     steps:  3000, failure\n",
      "[Episode   197]  total reward: -61320.4105692     steps:  3000, failure\n",
      "[Episode   198]  total reward: -59455.0119498     steps:  3000, failure\n",
      "[Episode   199]  total reward: -62728.0     steps:  3000, failure\n",
      "[Episode   200]  total reward: -44806.9191525     steps:  3000, failure\n",
      "[Episode   201]  total reward: -37488.9191525     steps:  3000, failure\n",
      "[Episode   202]  total reward: -38576.0     steps:  3000, failure\n",
      "[Episode   203]  total reward: -38038.4105692     steps:  3000, failure\n",
      "[Episode   204]  total reward: -54666.4105692     steps:  3000, failure\n",
      "[Episode   205]  total reward: -63669.4105692     steps:  3000, failure\n",
      "[Episode   206]  total reward: -40216.9191525     steps:  3000, failure\n",
      "[Episode   207]  total reward: -60426.4105692     steps:  3000, failure\n",
      "[Episode   208]  total reward: -62323.0119498     steps:  3000, failure\n",
      "[Episode   209]  total reward: -41459.5989095     steps:  3000, failure\n",
      "[Episode   210]  total reward: -39352.0     steps:  3000, failure\n",
      "[Episode   211]  total reward: -38985.4105692     steps:  3000, failure\n",
      "[Episode   212]  total reward: -62940.0119498     steps:  3000, failure\n",
      "[Episode   213]  total reward: -38209.9191525     steps:  3000, failure\n",
      "[Episode   214]  total reward: -38588.9191525     steps:  3000, failure\n",
      "[Episode   215]  total reward: -36416.9191525     steps:  3000, failure\n",
      "[Episode   216]  total reward: -35892.9191525     steps:  3000, failure\n",
      "[Episode   217]  total reward: -35952.0     steps:  3000, failure\n",
      "[Episode   218]  total reward: -64755.0     steps:  3000, failure\n",
      "[Episode   219]  total reward: -62198.5989095     steps:  3000, failure\n",
      "[Episode   220]  total reward: -57278.0     steps:  3000, failure\n",
      "[Episode   221]  total reward: -48427.0     steps:  3000, failure\n",
      "[Episode   222]  total reward: -35758.5989095     steps:  3000, failure\n",
      "[Episode   223]  total reward: -35591.5989095     steps:  3000, failure\n",
      "[Episode   224]  total reward: -64084.4105692     steps:  3000, failure\n",
      "[Episode   225]  total reward: -55865.0     steps:  3000, failure\n",
      "[Episode   226]  total reward: -63416.0     steps:  3000, failure\n",
      "[Episode   227]  total reward: -62506.4105692     steps:  3000, failure\n",
      "[Episode   228]  total reward: -55453.4105692     steps:  3000, failure\n",
      "[Episode   229]  total reward: -37225.4105692     steps:  3000, failure\n",
      "[Episode   230]  total reward: -63248.9191525     steps:  3000, failure\n",
      "[Episode   231]  total reward: -55987.0119498     steps:  3000, failure\n",
      "[Episode   232]  total reward: -50503.5989095     steps:  3000, failure\n",
      "[Episode   233]  total reward: -59313.9191525     steps:  3000, failure\n",
      "[Episode   234]  total reward: 921.080847462    steps:    27, success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   235]  total reward: -58956.5989095     steps:  3000, failure\n",
      "[Episode   236]  total reward: -38795.0     steps:  3000, failure\n",
      "[Episode   237]  total reward: -63158.0     steps:  3000, failure\n",
      "[Episode   238]  total reward: -39296.0     steps:  3000, failure\n",
      "[Episode   239]  total reward: -58214.0     steps:  3000, failure\n",
      "[Episode   240]  total reward: -64124.5989095     steps:  3000, failure\n",
      "[Episode   241]  total reward: -45581.0119498     steps:  3000, failure\n",
      "[Episode   242]  total reward: -1128.01194975    steps:   133, success\n",
      "[Episode   243]  total reward: -36056.5989095     steps:  3000, failure\n",
      "[Episode   244]  total reward: -35924.0     steps:  3000, failure\n",
      "[Episode   245]  total reward: -49216.9191525     steps:  3000, failure\n",
      "[Episode   246]  total reward: -62177.0119498     steps:  3000, failure\n",
      "[Episode   247]  total reward: -64901.0     steps:  3000, failure\n",
      "[Episode   248]  total reward: -35808.0     steps:  3000, failure\n",
      "[Episode   249]  total reward: -63070.5989095     steps:  3000, failure\n",
      "[Episode   250]  total reward: -2526.0    steps:   316, success\n",
      "[Episode   251]  total reward: -737.410569172    steps:   109, success\n",
      "[Episode   252]  total reward: -56964.0119498     steps:  3000, failure\n",
      "[Episode   253]  total reward: -65616.4105692     steps:  3000, failure\n",
      "[Episode   254]  total reward: -64991.4105692     steps:  3000, failure\n",
      "[Episode   255]  total reward: -64188.9191525     steps:  3000, failure\n",
      "[Episode   256]  total reward: -65745.4105692     steps:  3000, failure\n",
      "[Episode   257]  total reward: -64520.0     steps:  3000, failure\n",
      "[Episode   258]  total reward: -63724.5989095     steps:  3000, failure\n",
      "[Episode   259]  total reward: -63836.0     steps:  3000, failure\n",
      "[Episode   260]  total reward: -64371.5989095     steps:  3000, failure\n",
      "[Episode   261]  total reward: -65256.0     steps:  3000, failure\n",
      "[Episode   262]  total reward: -62746.0     steps:  3000, failure\n",
      "[Episode   263]  total reward: -64707.4105692     steps:  3000, failure\n",
      "[Episode   264]  total reward: -55919.9191525     steps:  3000, failure\n",
      "[Episode   265]  total reward: -54637.4105692     steps:  3000, failure\n",
      "[Episode   266]  total reward: -35722.5989095     steps:  3000, failure\n",
      "[Episode   267]  total reward: -60301.0     steps:  3000, failure\n",
      "[Episode   268]  total reward: -64783.4105692     steps:  3000, failure\n",
      "[Episode   269]  total reward: -61678.4105692     steps:  3000, failure\n",
      "[Episode   270]  total reward: -62637.0     steps:  3000, failure\n",
      "[Episode   271]  total reward: -64993.0     steps:  3000, failure\n",
      "[Episode   272]  total reward: -51819.5989095     steps:  3000, failure\n",
      "[Episode   273]  total reward: -61283.5989095     steps:  3000, failure\n",
      "[Episode   274]  total reward: -65145.4105692     steps:  3000, failure\n",
      "[Episode   275]  total reward: -61639.0119498     steps:  3000, failure\n",
      "[Episode   276]  total reward: -61714.9191525     steps:  3000, failure\n",
      "[Episode   277]  total reward: -65444.9191525     steps:  3000, failure\n",
      "[Episode   278]  total reward: -64683.4105692     steps:  3000, failure\n",
      "[Episode   279]  total reward: -56660.9191525     steps:  3000, failure\n",
      "[Episode   280]  total reward: -59132.9191525     steps:  3000, failure\n",
      "[Episode   281]  total reward: -46364.5989095     steps:  3000, failure\n",
      "[Episode   282]  total reward: -62261.0     steps:  3000, failure\n",
      "[Episode   283]  total reward: -64326.9191525     steps:  3000, failure\n",
      "[Episode   284]  total reward: -63136.9191525     steps:  3000, failure\n",
      "[Episode   285]  total reward: -62421.0     steps:  3000, failure\n",
      "[Episode   286]  total reward: -65104.4105692     steps:  3000, failure\n",
      "[Episode   287]  total reward: -65078.0     steps:  3000, failure\n",
      "[Episode   288]  total reward: -62071.0     steps:  3000, failure\n",
      "[Episode   289]  total reward: -64303.0     steps:  3000, failure\n",
      "[Episode   290]  total reward: -41576.5989095     steps:  3000, failure\n",
      "[Episode   291]  total reward: -56365.5989095     steps:  3000, failure\n",
      "[Episode   292]  total reward: -65272.0     steps:  3000, failure\n",
      "[Episode   293]  total reward: -62061.0119498     steps:  3000, failure\n",
      "[Episode   294]  total reward: -57819.0     steps:  3000, failure\n",
      "[Episode   295]  total reward: -65293.0     steps:  3000, failure\n",
      "[Episode   296]  total reward: -60140.0     steps:  3000, failure\n",
      "[Episode   297]  total reward: -44701.5989095     steps:  3000, failure\n",
      "[Episode   298]  total reward: -65401.5989095     steps:  3000, failure\n",
      "[Episode   299]  total reward: -36470.5989095     steps:  3000, failure\n",
      "[Episode   300]  total reward: -43129.0     steps:  3000, failure\n",
      "[Episode   301]  total reward: -64967.9191525     steps:  3000, failure\n",
      "[Episode   302]  total reward: -1314.0    steps:   120, success\n",
      "[Episode   303]  total reward: -65412.0     steps:  3000, failure\n",
      "[Episode   304]  total reward: -64549.5989095     steps:  3000, failure\n",
      "[Episode   305]  total reward: -64368.0     steps:  3000, failure\n",
      "[Episode   306]  total reward: -65255.9191525     steps:  3000, failure\n",
      "[Episode   307]  total reward: -64714.0     steps:  3000, failure\n",
      "[Episode   308]  total reward: -63844.9191525     steps:  3000, failure\n",
      "[Episode   309]  total reward: -60919.9191525     steps:  3000, failure\n",
      "[Episode   310]  total reward: -57610.5989095     steps:  3000, failure\n",
      "[Episode   311]  total reward: -35132.4105692     steps:  3000, failure\n",
      "[Episode   312]  total reward: -38045.0     steps:  3000, failure\n",
      "[Episode   313]  total reward: -65530.0     steps:  3000, failure\n",
      "[Episode   314]  total reward: -62134.5989095     steps:  3000, failure\n",
      "[Episode   315]  total reward: -56283.9191525     steps:  3000, failure\n",
      "[Episode   316]  total reward: -64597.5989095     steps:  3000, failure\n",
      "[Episode   317]  total reward: -61900.0     steps:  3000, failure\n",
      "[Episode   318]  total reward: -65291.4105692     steps:  3000, failure\n",
      "[Episode   319]  total reward: -65175.0     steps:  3000, failure\n",
      "[Episode   320]  total reward: -61200.4105692     steps:  3000, failure\n",
      "[Episode   321]  total reward: -59943.0119498     steps:  3000, failure\n",
      "[Episode   322]  total reward: -65493.0     steps:  3000, failure\n",
      "[Episode   323]  total reward: -64969.4105692     steps:  3000, failure\n",
      "[Episode   324]  total reward: -64259.0     steps:  3000, failure\n",
      "[Episode   325]  total reward: -65496.5989095     steps:  3000, failure\n",
      "[Episode   326]  total reward: -62639.0     steps:  3000, failure\n",
      "[Episode   327]  total reward: -64262.0119498     steps:  3000, failure\n",
      "[Episode   328]  total reward: -64996.9191525     steps:  3000, failure\n",
      "[Episode   329]  total reward: -63217.4105692     steps:  3000, failure\n",
      "[Episode   330]  total reward: -65583.4105692     steps:  3000, failure\n",
      "[Episode   331]  total reward: 975.589430828    steps:    25, success\n",
      "[Episode   332]  total reward: -64378.4105692     steps:  3000, failure\n",
      "[Episode   333]  total reward: -65165.5989095     steps:  3000, failure\n",
      "[Episode   334]  total reward: -63952.9191525     steps:  3000, failure\n",
      "[Episode   335]  total reward: -51851.4105692     steps:  3000, failure\n",
      "[Episode   336]  total reward: -47680.5989095     steps:  3000, failure\n",
      "[Episode   337]  total reward: -41182.0     steps:  3000, failure\n",
      "[Episode   338]  total reward: -40928.0     steps:  3000, failure\n",
      "[Episode   339]  total reward: -483.0    steps:   110, success\n",
      "[Episode   340]  total reward: 919.589430828    steps:    25, success\n",
      "[Episode   341]  total reward: -65706.4105692     steps:  3000, failure\n",
      "[Episode   342]  total reward: -64378.0119498     steps:  3000, failure\n",
      "[Episode   343]  total reward: -65643.9191525     steps:  3000, failure\n",
      "[Episode   344]  total reward: 912.401090505    steps:    23, success\n",
      "[Episode   345]  total reward: 908.401090505    steps:    57, success\n",
      "[Episode   346]  total reward: 823.0    steps:    45, success\n",
      "[Episode   347]  total reward: -64667.9191525     steps:  3000, failure\n",
      "[Episode   348]  total reward: 478.589430828    steps:    42, success\n",
      "[Episode   349]  total reward: 925.988050249    steps:    27, success\n",
      "[Episode   350]  total reward: 980.0    steps:    16, success\n",
      "[Episode   351]  total reward: -65172.0119498     steps:  3000, failure\n",
      "[Episode   352]  total reward: -65736.4105692     steps:  3000, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   353]  total reward: -65708.9191525     steps:  3000, failure\n",
      "[Episode   354]  total reward: -6880.41056917    steps:   388, success\n",
      "[Episode   355]  total reward: -65552.4105692     steps:  3000, failure\n",
      "[Episode   356]  total reward: 825.988050249    steps:    33, success\n",
      "[Episode   357]  total reward: 942.0    steps:    25, success\n",
      "[Episode   358]  total reward: -65368.5989095     steps:  3000, failure\n",
      "[Episode   359]  total reward: 944.0    steps:    21, success\n",
      "[Episode   360]  total reward: 959.0    steps:    17, success\n",
      "[Episode   361]  total reward: 917.589430828    steps:    22, success\n",
      "[Episode   362]  total reward: 939.0    steps:    23, success\n",
      "[Episode   363]  total reward: 937.988050249    steps:    25, success\n",
      "[Episode   364]  total reward: 967.988050249    steps:    16, success\n",
      "[Episode   365]  total reward: 962.589430828    steps:    16, success\n",
      "[Episode   366]  total reward: -65232.0119498     steps:  3000, failure\n",
      "[Episode   367]  total reward: 917.589430828    steps:    31, success\n",
      "[Episode   368]  total reward: -64126.4105692     steps:  3000, failure\n",
      "[Episode   369]  total reward: -20029.4105692    steps:   985, success\n",
      "[Episode   370]  total reward: -64941.4105692     steps:  3000, failure\n",
      "[Episode   371]  total reward: -65509.4105692     steps:  3000, failure\n",
      "[Episode   372]  total reward: -62117.4105692     steps:  3000, failure\n",
      "[Episode   373]  total reward: -39780.4105692    steps:  1876, success\n",
      "[Episode   374]  total reward: -65474.4105692     steps:  3000, failure\n",
      "[Episode   375]  total reward: -65735.5989095     steps:  3000, failure\n",
      "[Episode   376]  total reward: -241.919152538    steps:    67, success\n",
      "[Episode   377]  total reward: 582.401090505    steps:    30, success\n",
      "[Episode   378]  total reward: -65686.5989095     steps:  3000, failure\n",
      "[Episode   379]  total reward: 857.0    steps:    26, success\n",
      "[Episode   380]  total reward: -65666.4105692     steps:  3000, failure\n",
      "[Episode   381]  total reward: -65726.0     steps:  3000, failure\n",
      "[Episode   382]  total reward: -64554.0     steps:  3000, failure\n",
      "[Episode   383]  total reward: -65582.0     steps:  3000, failure\n",
      "[Episode   384]  total reward: -64591.5989095     steps:  3000, failure\n",
      "[Episode   385]  total reward: -64708.5989095     steps:  3000, failure\n",
      "[Episode   386]  total reward: -25243.0    steps:  1212, success\n",
      "[Episode   387]  total reward: -65298.0     steps:  3000, failure\n",
      "[Episode   388]  total reward: 902.401090505    steps:    22, success\n",
      "[Episode   389]  total reward: 906.401090505    steps:    25, success\n",
      "[Episode   390]  total reward: -275.598909495    steps:    77, success\n",
      "[Episode   391]  total reward: 741.0    steps:    39, success\n",
      "[Episode   392]  total reward: 169.401090505    steps:    54, success\n",
      "[Episode   393]  total reward: -65646.9191525     steps:  3000, failure\n",
      "[Episode   394]  total reward: 859.401090505    steps:    27, success\n",
      "[Episode   395]  total reward: -65589.5989095     steps:  3000, failure\n",
      "[Episode   396]  total reward: -65105.5989095     steps:  3000, failure\n",
      "[Episode   397]  total reward: -63188.0     steps:  3000, failure\n",
      "[Episode   398]  total reward: -61509.0     steps:  3000, failure\n",
      "[Episode   399]  total reward: -65143.5989095     steps:  3000, failure\n",
      "[Episode   400]  total reward: -65130.5989095     steps:  3000, failure\n",
      "[Episode   401]  total reward: -65162.4105692     steps:  3000, failure\n",
      "[Episode   402]  total reward: -65217.4105692     steps:  3000, failure\n",
      "[Episode   403]  total reward: -64617.0     steps:  3000, failure\n",
      "[Episode   404]  total reward: -65772.5989095     steps:  3000, failure\n",
      "[Episode   405]  total reward: -65644.9191525     steps:  3000, failure\n",
      "[Episode   406]  total reward: -64989.0     steps:  3000, failure\n",
      "[Episode   407]  total reward: -54570.9191525     steps:  3000, failure\n",
      "[Episode   408]  total reward: -42411.4105692     steps:  3000, failure\n",
      "[Episode   409]  total reward: -50556.0     steps:  3000, failure\n",
      "[Episode   410]  total reward: -57791.0     steps:  3000, failure\n",
      "[Episode   411]  total reward: -61178.4105692     steps:  3000, failure\n",
      "[Episode   412]  total reward: -45422.4105692     steps:  3000, failure\n",
      "[Episode   413]  total reward: -40784.9191525     steps:  3000, failure\n",
      "[Episode   414]  total reward: -60372.5989095     steps:  3000, failure\n",
      "[Episode   415]  total reward: -62976.9191525     steps:  3000, failure\n",
      "[Episode   416]  total reward: -65122.5989095     steps:  3000, failure\n",
      "[Episode   417]  total reward: -65613.4105692     steps:  3000, failure\n",
      "[Episode   418]  total reward: -64288.9191525     steps:  3000, failure\n",
      "[Episode   419]  total reward: -63300.9191525     steps:  3000, failure\n",
      "[Episode   420]  total reward: -35932.5989095     steps:  3000, failure\n",
      "[Episode   421]  total reward: -60390.5989095     steps:  3000, failure\n",
      "[Episode   422]  total reward: -41757.4105692     steps:  3000, failure\n",
      "[Episode   423]  total reward: -519.410569172    steps:    89, success\n",
      "[Episode   424]  total reward: -98.410569172    steps:    76, success\n",
      "[Episode   425]  total reward: -54618.4105692     steps:  3000, failure\n",
      "[Episode   426]  total reward: -65865.4105692     steps:  3000, failure\n",
      "[Episode   427]  total reward: -65833.4105692     steps:  3000, failure\n",
      "[Episode   428]  total reward: -65517.4105692     steps:  3000, failure\n",
      "[Episode   429]  total reward: -64911.0     steps:  3000, failure\n",
      "[Episode   430]  total reward: -64839.4105692     steps:  3000, failure\n",
      "[Episode   431]  total reward: -57327.0119498     steps:  3000, failure\n",
      "[Episode   432]  total reward: -65158.5989095     steps:  3000, failure\n",
      "[Episode   433]  total reward: -61287.4105692     steps:  3000, failure\n",
      "[Episode   434]  total reward: -62872.0119498     steps:  3000, failure\n",
      "[Episode   435]  total reward: -64580.0119498     steps:  3000, failure\n",
      "[Episode   436]  total reward: -63581.0119498     steps:  3000, failure\n",
      "[Episode   437]  total reward: -65480.5989095     steps:  3000, failure\n",
      "[Episode   438]  total reward: -65733.5989095     steps:  3000, failure\n",
      "[Episode   439]  total reward: -57843.4105692     steps:  3000, failure\n",
      "[Episode   440]  total reward: -51012.5989095     steps:  3000, failure\n",
      "[Episode   441]  total reward: -62479.4105692     steps:  3000, failure\n",
      "[Episode   442]  total reward: -65526.5989095     steps:  3000, failure\n",
      "[Episode   443]  total reward: -65820.9191525     steps:  3000, failure\n",
      "[Episode   444]  total reward: -65625.9191525     steps:  3000, failure\n",
      "[Episode   445]  total reward: -50129.9191525     steps:  3000, failure\n",
      "[Episode   446]  total reward: -64537.4105692     steps:  3000, failure\n",
      "[Episode   447]  total reward: 594.0    steps:    53, success\n",
      "[Episode   448]  total reward: -65602.4105692     steps:  3000, failure\n",
      "[Episode   449]  total reward: -65254.0     steps:  3000, failure\n",
      "[Episode   450]  total reward: -3015.5989095    steps:   215, success\n",
      "[Episode   451]  total reward: -65645.9191525     steps:  3000, failure\n",
      "[Episode   452]  total reward: -65722.5989095     steps:  3000, failure\n",
      "[Episode   453]  total reward: -3104.5989095    steps:   201, success\n",
      "[Episode   454]  total reward: 981.988050249    steps:    24, success\n",
      "[Episode   455]  total reward: -128.598909495    steps:    63, success\n",
      "[Episode   456]  total reward: 919.988050249    steps:    25, success\n",
      "[Episode   457]  total reward: 969.988050249    steps:    29, success\n",
      "[Episode   458]  total reward: 969.988050249    steps:    28, success\n",
      "[Episode   459]  total reward: 987.988050249    steps:    22, success\n",
      "[Episode   460]  total reward: 941.988050249    steps:    31, success\n",
      "[Episode   461]  total reward: 993.988050249    steps:    23, success\n",
      "[Episode   462]  total reward: 951.988050249    steps:    25, success\n",
      "[Episode   463]  total reward: 985.589430828    steps:    21, success\n",
      "[Episode   464]  total reward: 960.988050249    steps:    31, success\n",
      "[Episode   465]  total reward: 991.988050249    steps:    19, success\n",
      "[Episode   466]  total reward: 982.988050249    steps:    22, success\n",
      "[Episode   467]  total reward: 986.988050249    steps:    16, success\n",
      "[Episode   468]  total reward: 987.589430828    steps:    17, success\n",
      "[Episode   469]  total reward: 981.988050249    steps:    18, success\n",
      "[Episode   470]  total reward: 983.988050249    steps:    23, success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   471]  total reward: 976.080847462    steps:    30, success\n",
      "[Episode   472]  total reward: 997.988050249    steps:    30, success\n",
      "[Episode   473]  total reward: 987.988050249    steps:    18, success\n",
      "[Episode   474]  total reward: 956.988050249    steps:    18, success\n",
      "[Episode   475]  total reward: 952.080847462    steps:    23, success\n",
      "[Episode   476]  total reward: 989.0    steps:    15, success\n",
      "[Episode   477]  total reward: 962.0    steps:    20, success\n",
      "[Episode   478]  total reward: 972.988050249    steps:    17, success\n",
      "[Episode   479]  total reward: 986.988050249    steps:    16, success\n",
      "[Episode   480]  total reward: 981.988050249    steps:    24, success\n",
      "[Episode   481]  total reward: 967.401090505    steps:    27, success\n",
      "[Episode   482]  total reward: 981.988050249    steps:    21, success\n",
      "[Episode   483]  total reward: 988.988050249    steps:    18, success\n",
      "[Episode   484]  total reward: 942.988050249    steps:    22, success\n",
      "[Episode   485]  total reward: 996.988050249    steps:    22, success\n",
      "[Episode   486]  total reward: 992.988050249    steps:    18, success\n",
      "[Episode   487]  total reward: 947.988050249    steps:    27, success\n",
      "[Episode   488]  total reward: 981.988050249    steps:    15, success\n",
      "[Episode   489]  total reward: 964.401090505    steps:    24, success\n",
      "[Episode   490]  total reward: 983.988050249    steps:    17, success\n",
      "[Episode   491]  total reward: -64765.0119498     steps:  3000, failure\n",
      "[Episode   492]  total reward: -63249.9191525     steps:  3000, failure\n",
      "[Episode   493]  total reward: 978.988050249    steps:    17, success\n",
      "[Episode   494]  total reward: 977.988050249    steps:    18, success\n",
      "[Episode   495]  total reward: -61558.0119498     steps:  3000, failure\n",
      "[Episode   496]  total reward: -65821.0     steps:  3000, failure\n",
      "[Episode   497]  total reward: -65370.0     steps:  3000, failure\n",
      "[Episode   498]  total reward: -57752.9191525     steps:  3000, failure\n",
      "[Episode   499]  total reward: -63558.5989095     steps:  3000, failure\n",
      "[Episode   500]  total reward: -65206.4105692     steps:  3000, failure\n",
      "[Episode   501]  total reward: -59667.9191525     steps:  3000, failure\n",
      "[Episode   502]  total reward: -56475.4105692     steps:  3000, failure\n",
      "[Episode   503]  total reward: -650.0    steps:    99, success\n",
      "[Episode   504]  total reward: 236.589430828    steps:    46, success\n",
      "[Episode   505]  total reward: -35.5989094951    steps:    61, success\n",
      "[Episode   506]  total reward: -54138.0     steps:  3000, failure\n",
      "[Episode   507]  total reward: -62448.0     steps:  3000, failure\n",
      "[Episode   508]  total reward: -63144.5989095     steps:  3000, failure\n",
      "[Episode   509]  total reward: 951.988050249    steps:    25, success\n",
      "[Episode   510]  total reward: 993.988050249    steps:    16, success\n",
      "[Episode   511]  total reward: -65261.0119498     steps:  3000, failure\n",
      "[Episode   512]  total reward: -65369.4105692     steps:  3000, failure\n",
      "[Episode   513]  total reward: -65211.9191525     steps:  3000, failure\n",
      "[Episode   514]  total reward: -65289.4105692     steps:  3000, failure\n",
      "[Episode   515]  total reward:  92.0    steps:    88, success\n",
      "[Episode   516]  total reward: 28.4010905049    steps:    62, success\n",
      "[Episode   517]  total reward: 665.401090505    steps:    46, success\n",
      "[Episode   518]  total reward: 634.080847462    steps:    51, success\n",
      "[Episode   519]  total reward: -65313.5989095     steps:  3000, failure\n",
      "[Episode   520]  total reward: -63700.5989095     steps:  3000, failure\n",
      "[Episode   521]  total reward: -65502.0     steps:  3000, failure\n",
      "[Episode   522]  total reward: -65808.0     steps:  3000, failure\n",
      "[Episode   523]  total reward: -65770.9191525     steps:  3000, failure\n",
      "[Episode   524]  total reward: 532.589430828    steps:    43, success\n",
      "[Episode   525]  total reward: 493.401090505    steps:    51, success\n",
      "[Episode   526]  total reward: -65313.5989095     steps:  3000, failure\n",
      "[Episode   527]  total reward: -65427.4105692     steps:  3000, failure\n",
      "[Episode   528]  total reward: -64480.0     steps:  3000, failure\n",
      "[Episode   529]  total reward: -65691.4105692     steps:  3000, failure\n",
      "[Episode   530]  total reward: -61880.9191525     steps:  3000, failure\n",
      "[Episode   531]  total reward: -60304.9191525     steps:  3000, failure\n",
      "[Episode   532]  total reward: -61521.9191525     steps:  3000, failure\n",
      "[Episode   533]  total reward: 242.080847462    steps:    67, success\n",
      "[Episode   534]  total reward: -63639.5989095     steps:  3000, failure\n",
      "[Episode   535]  total reward: -64741.4105692     steps:  3000, failure\n",
      "[Episode   536]  total reward: -49329.9191525     steps:  3000, failure\n",
      "[Episode   537]  total reward: -2058.5989095    steps:   159, success\n",
      "[Episode   538]  total reward: -63877.4105692     steps:  3000, failure\n",
      "[Episode   539]  total reward: -65782.5989095     steps:  3000, failure\n",
      "[Episode   540]  total reward: -45638.0     steps:  3000, failure\n",
      "[Episode   541]  total reward: -48028.0     steps:  3000, failure\n",
      "[Episode   542]  total reward: -54342.9191525     steps:  3000, failure\n",
      "[Episode   543]  total reward: -52292.0     steps:  3000, failure\n",
      "[Episode   544]  total reward: -65271.0     steps:  3000, failure\n",
      "[Episode   545]  total reward: 363.080847462    steps:    46, success\n",
      "[Episode   546]  total reward: 631.988050249    steps:    41, success\n",
      "[Episode   547]  total reward: 985.988050249    steps:    19, success\n",
      "[Episode   548]  total reward: 985.988050249    steps:    15, success\n",
      "[Episode   549]  total reward: 992.589430828    steps:    28, success\n",
      "[Episode   550]  total reward: 983.988050249    steps:    19, success\n",
      "[Episode   551]  total reward: 979.988050249    steps:    22, success\n",
      "[Episode   552]  total reward: 981.988050249    steps:    17, success\n",
      "[Episode   553]  total reward: 915.0    steps:    21, success\n",
      "[Episode   554]  total reward: 979.988050249    steps:    17, success\n",
      "[Episode   555]  total reward: -51548.0119498     steps:  3000, failure\n",
      "[Episode   556]  total reward: -42849.4105692     steps:  3000, failure\n",
      "[Episode   557]  total reward: -62964.0     steps:  3000, failure\n",
      "[Episode   558]  total reward: -65504.9191525     steps:  3000, failure\n",
      "[Episode   559]  total reward: -62880.0     steps:  3000, failure\n",
      "[Episode   560]  total reward: -65214.0     steps:  3000, failure\n",
      "[Episode   561]  total reward: -316.598909495    steps:    93, success\n",
      "[Episode   562]  total reward: -65418.5989095     steps:  3000, failure\n",
      "[Episode   563]  total reward: 995.0    steps:    17, success\n",
      "[Episode   564]  total reward: 983.988050249    steps:    19, success\n",
      "[Episode   565]  total reward: 984.988050249    steps:    16, success\n",
      "[Episode   566]  total reward: 981.988050249    steps:    17, success\n",
      "[Episode   567]  total reward: 992.988050249    steps:    16, success\n",
      "[Episode   568]  total reward: 974.988050249    steps:    24, success\n",
      "[Episode   569]  total reward: -63845.0119498     steps:  3000, failure\n",
      "[Episode   570]  total reward: -63373.0119498     steps:  3000, failure\n",
      "[Episode   571]  total reward: -65290.0     steps:  3000, failure\n",
      "[Episode   572]  total reward: -65885.4105692     steps:  3000, failure\n",
      "[Episode   573]  total reward: -65514.9191525     steps:  3000, failure\n",
      "[Episode   574]  total reward: -65274.0     steps:  3000, failure\n",
      "[Episode   575]  total reward: -65578.9191525     steps:  3000, failure\n",
      "[Episode   576]  total reward: -65560.0     steps:  3000, failure\n",
      "[Episode   577]  total reward: -64206.5989095     steps:  3000, failure\n",
      "[Episode   578]  total reward: -62838.4105692     steps:  3000, failure\n",
      "[Episode   579]  total reward: -65326.0     steps:  3000, failure\n",
      "[Episode   580]  total reward: -64281.9191525     steps:  3000, failure\n",
      "[Episode   581]  total reward: -64399.0     steps:  3000, failure\n",
      "[Episode   582]  total reward: -64764.5989095     steps:  3000, failure\n",
      "[Episode   583]  total reward: -64164.9191525     steps:  3000, failure\n",
      "[Episode   584]  total reward: -65865.9191525     steps:  3000, failure\n",
      "[Episode   585]  total reward: -6655.5989095    steps:   604, success\n",
      "[Episode   586]  total reward: -65885.4105692     steps:  3000, failure\n",
      "[Episode   587]  total reward: -65548.4105692     steps:  3000, failure\n",
      "[Episode   588]  total reward: -63730.0     steps:  3000, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   589]  total reward: -65865.4105692     steps:  3000, failure\n",
      "[Episode   590]  total reward: -54734.0     steps:  3000, failure\n",
      "[Episode   591]  total reward: -56022.0119498     steps:  3000, failure\n",
      "[Episode   592]  total reward: -35852.5989095     steps:  3000, failure\n",
      "[Episode   593]  total reward: -35886.9191525     steps:  3000, failure\n",
      "[Episode   594]  total reward: -35916.9191525     steps:  3000, failure\n",
      "[Episode   595]  total reward: -54048.9191525     steps:  3000, failure\n",
      "[Episode   596]  total reward: -35810.5989095     steps:  3000, failure\n",
      "[Episode   597]  total reward: -65493.4105692     steps:  3000, failure\n",
      "[Episode   598]  total reward: -39216.9191525     steps:  3000, failure\n",
      "[Episode   599]  total reward: -35914.9191525     steps:  3000, failure\n",
      "[Episode   600]  total reward: -35950.5989095     steps:  3000, failure\n",
      "[Episode   601]  total reward: -65885.4105692     steps:  3000, failure\n",
      "[Episode   602]  total reward: -42305.4105692     steps:  3000, failure\n",
      "[Episode   603]  total reward: -38538.9191525     steps:  3000, failure\n",
      "[Episode   604]  total reward: -38778.0     steps:  3000, failure\n",
      "[Episode   605]  total reward: -47833.9191525     steps:  3000, failure\n",
      "[Episode   606]  total reward: -49149.5989095     steps:  3000, failure\n",
      "[Episode   607]  total reward: -64118.4105692     steps:  3000, failure\n",
      "[Episode   608]  total reward: -63581.0     steps:  3000, failure\n",
      "[Episode   609]  total reward: -64417.9191525     steps:  3000, failure\n",
      "[Episode   610]  total reward: -464.0    steps:    91, success\n",
      "[Episode   611]  total reward: -61727.0     steps:  3000, failure\n",
      "[Episode   612]  total reward: -54088.5989095     steps:  3000, failure\n",
      "[Episode   613]  total reward: -60960.0     steps:  3000, failure\n",
      "[Episode   614]  total reward: -62278.5989095     steps:  3000, failure\n",
      "[Episode   615]  total reward: -57560.9191525     steps:  3000, failure\n",
      "[Episode   616]  total reward: -63099.4105692     steps:  3000, failure\n",
      "[Episode   617]  total reward: -63975.4105692     steps:  3000, failure\n",
      "[Episode   618]  total reward: -61541.9191525     steps:  3000, failure\n",
      "[Episode   619]  total reward: -65538.4105692     steps:  3000, failure\n",
      "[Episode   620]  total reward: -63499.4105692     steps:  3000, failure\n",
      "[Episode   621]  total reward: -65760.9191525     steps:  3000, failure\n",
      "[Episode   622]  total reward: -65544.0     steps:  3000, failure\n",
      "[Episode   623]  total reward: -65254.0     steps:  3000, failure\n",
      "[Episode   624]  total reward: -65352.4105692     steps:  3000, failure\n",
      "[Episode   625]  total reward: -63828.5989095     steps:  3000, failure\n",
      "[Episode   626]  total reward: -64503.4105692     steps:  3000, failure\n",
      "[Episode   627]  total reward: -7301.01194975    steps:   417, success\n",
      "[Episode   628]  total reward: -57796.9191525     steps:  3000, failure\n",
      "[Episode   629]  total reward: -62060.9191525     steps:  3000, failure\n",
      "[Episode   630]  total reward: -45173.4105692     steps:  3000, failure\n",
      "[Episode   631]  total reward: -64388.9191525     steps:  3000, failure\n",
      "[Episode   632]  total reward: -63782.0     steps:  3000, failure\n",
      "[Episode   633]  total reward: -65035.4105692     steps:  3000, failure\n",
      "[Episode   634]  total reward: 21.9880502489    steps:    62, success\n",
      "[Episode   635]  total reward: 433.988050249    steps:    60, success\n",
      "[Episode   636]  total reward: 511.401090505    steps:    38, success\n",
      "[Episode   637]  total reward: -64713.0     steps:  3000, failure\n",
      "[Episode   638]  total reward: -38798.4105692     steps:  3000, failure\n",
      "[Episode   639]  total reward: -65364.4105692     steps:  3000, failure\n",
      "[Episode   640]  total reward: -65320.9191525     steps:  3000, failure\n",
      "[Episode   641]  total reward: -945.410569172    steps:   149, success\n",
      "[Episode   642]  total reward: -53982.5989095     steps:  3000, failure\n",
      "[Episode   643]  total reward: -35974.9191525     steps:  3000, failure\n",
      "[Episode   644]  total reward: -35970.5989095     steps:  3000, failure\n",
      "[Episode   645]  total reward: -47880.9191525     steps:  3000, failure\n",
      "[Episode   646]  total reward: -65509.4105692     steps:  3000, failure\n",
      "[Episode   647]  total reward: -65360.0119498     steps:  3000, failure\n",
      "[Episode   648]  total reward: -65765.4105692     steps:  3000, failure\n",
      "[Episode   649]  total reward: -65416.5989095     steps:  3000, failure\n",
      "[Episode   650]  total reward: -65533.4105692     steps:  3000, failure\n",
      "[Episode   651]  total reward: -42804.0     steps:  3000, failure\n",
      "[Episode   652]  total reward: -62680.9191525     steps:  3000, failure\n",
      "[Episode   653]  total reward: -62235.0     steps:  3000, failure\n",
      "[Episode   654]  total reward: -65466.0     steps:  3000, failure\n",
      "[Episode   655]  total reward: -65832.4105692     steps:  3000, failure\n",
      "[Episode   656]  total reward: -65099.9191525     steps:  3000, failure\n",
      "[Episode   657]  total reward: -272.0    steps:    79, success\n",
      "[Episode   658]  total reward: -65502.0     steps:  3000, failure\n",
      "[Episode   659]  total reward: -56979.9191525     steps:  3000, failure\n",
      "[Episode   660]  total reward: -45808.9191525     steps:  3000, failure\n",
      "[Episode   661]  total reward: -64308.9191525     steps:  3000, failure\n",
      "[Episode   662]  total reward: -62730.0     steps:  3000, failure\n",
      "[Episode   663]  total reward: 875.589430828    steps:    18, success\n",
      "[Episode   664]  total reward: -8106.91915254    steps:   473, success\n",
      "[Episode   665]  total reward: -61745.9191525     steps:  3000, failure\n",
      "[Episode   666]  total reward: -65354.5989095     steps:  3000, failure\n",
      "[Episode   667]  total reward: -55115.0     steps:  3000, failure\n",
      "[Episode   668]  total reward: -61040.9191525     steps:  3000, failure\n",
      "[Episode   669]  total reward: -65227.0     steps:  3000, failure\n",
      "[Episode   670]  total reward: -65491.4105692     steps:  3000, failure\n",
      "[Episode   671]  total reward: -64547.4105692     steps:  3000, failure\n",
      "[Episode   672]  total reward: -65047.4105692     steps:  3000, failure\n",
      "[Episode   673]  total reward: 413.080847462    steps:    54, success\n",
      "[Episode   674]  total reward: -65630.4105692     steps:  3000, failure\n",
      "[Episode   675]  total reward: -65112.5989095     steps:  3000, failure\n",
      "[Episode   676]  total reward: -65855.9191525     steps:  3000, failure\n",
      "[Episode   677]  total reward: -65805.4105692     steps:  3000, failure\n",
      "[Episode   678]  total reward: -64485.9191525     steps:  3000, failure\n",
      "[Episode   679]  total reward: -2425.01194975    steps:   199, success\n",
      "[Episode   680]  total reward: -65591.4105692     steps:  3000, failure\n",
      "[Episode   681]  total reward: -54.5989094951    steps:    79, success\n",
      "[Episode   682]  total reward: -55413.0119498     steps:  3000, failure\n",
      "[Episode   683]  total reward: -57276.9191525     steps:  3000, failure\n",
      "[Episode   684]  total reward: -42845.4105692     steps:  3000, failure\n",
      "[Episode   685]  total reward: -61922.5989095     steps:  3000, failure\n",
      "[Episode   686]  total reward: -54262.0     steps:  3000, failure\n",
      "[Episode   687]  total reward: -40357.0     steps:  3000, failure\n",
      "[Episode   688]  total reward: 831.0    steps:    41, success\n",
      "[Episode   689]  total reward: -491.0    steps:   133, success\n",
      "[Episode   690]  total reward: 716.589430828    steps:    31, success\n",
      "[Episode   691]  total reward: 982.401090505    steps:    23, success\n",
      "[Episode   692]  total reward: -7884.5989095    steps:   538, success\n",
      "[Episode   693]  total reward: -47570.0     steps:  3000, failure\n",
      "[Episode   694]  total reward: -63113.0119498     steps:  3000, failure\n",
      "[Episode   695]  total reward: -65721.4105692     steps:  3000, failure\n",
      "[Episode   696]  total reward: -65718.4105692     steps:  3000, failure\n",
      "[Episode   697]  total reward: -65635.4105692     steps:  3000, failure\n",
      "[Episode   698]  total reward: -65336.0     steps:  3000, failure\n",
      "[Episode   699]  total reward: -6293.5989095    steps:   417, success\n",
      "[Episode   700]  total reward: -7378.5989095    steps:   398, success\n",
      "[Episode   701]  total reward: -65156.5989095     steps:  3000, failure\n",
      "[Episode   702]  total reward: -61371.5989095     steps:  3000, failure\n",
      "[Episode   703]  total reward: -63490.0119498     steps:  3000, failure\n",
      "[Episode   704]  total reward: 384.589430828    steps:    44, success\n",
      "[Episode   705]  total reward: -64477.0119498     steps:  3000, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   706]  total reward: -65715.4105692     steps:  3000, failure\n",
      "[Episode   707]  total reward: -62768.9191525     steps:  3000, failure\n",
      "[Episode   708]  total reward: -65342.5989095     steps:  3000, failure\n",
      "[Episode   709]  total reward: -61917.4105692     steps:  3000, failure\n",
      "[Episode   710]  total reward: -64372.5989095     steps:  3000, failure\n",
      "[Episode   711]  total reward: -60392.5989095     steps:  3000, failure\n",
      "[Episode   712]  total reward: -1670.0    steps:   174, success\n",
      "[Episode   713]  total reward: -45715.0     steps:  3000, failure\n",
      "[Episode   714]  total reward: -49842.0     steps:  3000, failure\n",
      "[Episode   715]  total reward: -65680.9191525     steps:  3000, failure\n",
      "[Episode   716]  total reward: -65354.0119498     steps:  3000, failure\n",
      "[Episode   717]  total reward: -65751.4105692     steps:  3000, failure\n",
      "[Episode   718]  total reward: -65588.0     steps:  3000, failure\n",
      "[Episode   719]  total reward: -64777.0     steps:  3000, failure\n",
      "[Episode   720]  total reward: -51584.0     steps:  3000, failure\n",
      "[Episode   721]  total reward: -61569.0119498     steps:  3000, failure\n",
      "[Episode   722]  total reward: -64585.0     steps:  3000, failure\n",
      "[Episode   723]  total reward: -64303.5989095     steps:  3000, failure\n",
      "[Episode   724]  total reward: -61634.5989095     steps:  3000, failure\n",
      "[Episode   725]  total reward: -65092.0     steps:  3000, failure\n",
      "[Episode   726]  total reward: -59081.0     steps:  3000, failure\n",
      "[Episode   727]  total reward: -53095.5989095     steps:  3000, failure\n",
      "[Episode   728]  total reward: -38337.4105692     steps:  3000, failure\n",
      "[Episode   729]  total reward: -48054.0     steps:  3000, failure\n",
      "[Episode   730]  total reward: -35918.0     steps:  3000, failure\n",
      "[Episode   731]  total reward: -36698.0     steps:  3000, failure\n",
      "[Episode   732]  total reward: 625.401090505    steps:    55, success\n",
      "[Episode   733]  total reward:  -3.0    steps:    72, success\n",
      "[Episode   734]  total reward: -46183.0119498     steps:  3000, failure\n",
      "[Episode   735]  total reward: -62907.0119498     steps:  3000, failure\n",
      "[Episode   736]  total reward: -65255.4105692     steps:  3000, failure\n",
      "[Episode   737]  total reward: -64493.4105692     steps:  3000, failure\n",
      "[Episode   738]  total reward: -57307.4105692     steps:  3000, failure\n",
      "[Episode   739]  total reward: 59.4010905049    steps:    90, success\n",
      "[Episode   740]  total reward: -56240.0     steps:  3000, failure\n",
      "[Episode   741]  total reward: -57112.4105692     steps:  3000, failure\n",
      "[Episode   742]  total reward: -65486.5989095     steps:  3000, failure\n",
      "[Episode   743]  total reward: 540.589430828    steps:    49, success\n",
      "[Episode   744]  total reward: -54360.0119498     steps:  3000, failure\n",
      "[Episode   745]  total reward: -63251.9191525     steps:  3000, failure\n",
      "[Episode   746]  total reward: -65273.9191525     steps:  3000, failure\n",
      "[Episode   747]  total reward: -55471.9191525     steps:  3000, failure\n",
      "[Episode   748]  total reward: -64379.0     steps:  3000, failure\n",
      "[Episode   749]  total reward: -65543.4105692     steps:  3000, failure\n",
      "[Episode   750]  total reward: -65776.5989095     steps:  3000, failure\n",
      "[Episode   751]  total reward: -63773.4105692     steps:  3000, failure\n",
      "[Episode   752]  total reward: 748.401090505    steps:    42, success\n",
      "[Episode   753]  total reward: 431.401090505    steps:    59, success\n",
      "[Episode   754]  total reward: -63464.5989095     steps:  3000, failure\n",
      "[Episode   755]  total reward: -2197.41056917    steps:   166, success\n",
      "[Episode   756]  total reward: -65034.4105692     steps:  3000, failure\n",
      "[Episode   757]  total reward: -64134.9191525     steps:  3000, failure\n",
      "[Episode   758]  total reward: -63012.9191525     steps:  3000, failure\n",
      "[Episode   759]  total reward: -65085.9191525     steps:  3000, failure\n",
      "[Episode   760]  total reward: -62908.9191525     steps:  3000, failure\n",
      "[Episode   761]  total reward: -65081.9191525     steps:  3000, failure\n",
      "[Episode   762]  total reward: -65213.0     steps:  3000, failure\n",
      "[Episode   763]  total reward: -64893.9191525     steps:  3000, failure\n",
      "[Episode   764]  total reward: -65706.4105692     steps:  3000, failure\n",
      "[Episode   765]  total reward: -4782.91915254    steps:   299, success\n",
      "[Episode   766]  total reward: -64670.0     steps:  3000, failure\n",
      "[Episode   767]  total reward: -65650.0     steps:  3000, failure\n",
      "[Episode   768]  total reward: -61650.0     steps:  3000, failure\n",
      "[Episode   769]  total reward: -65006.0     steps:  3000, failure\n",
      "[Episode   770]  total reward: -62558.9191525     steps:  3000, failure\n",
      "[Episode   771]  total reward: -65753.9191525     steps:  3000, failure\n",
      "[Episode   772]  total reward: -65303.4105692     steps:  3000, failure\n",
      "[Episode   773]  total reward: -63438.5989095     steps:  3000, failure\n",
      "[Episode   774]  total reward: -65043.4105692     steps:  3000, failure\n",
      "[Episode   775]  total reward: -65404.9191525     steps:  3000, failure\n",
      "[Episode   776]  total reward: -60179.0     steps:  3000, failure\n",
      "[Episode   777]  total reward: -65627.4105692     steps:  3000, failure\n",
      "[Episode   778]  total reward: -65538.4105692     steps:  3000, failure\n",
      "[Episode   779]  total reward: -65420.0119498     steps:  3000, failure\n",
      "[Episode   780]  total reward: -65593.4105692     steps:  3000, failure\n",
      "[Episode   781]  total reward: -65865.4105692     steps:  3000, failure\n",
      "[Episode   782]  total reward: -65316.4105692     steps:  3000, failure\n",
      "[Episode   783]  total reward: -65700.9191525     steps:  3000, failure\n",
      "[Episode   784]  total reward: -64962.0     steps:  3000, failure\n",
      "[Episode   785]  total reward: -65565.4105692     steps:  3000, failure\n",
      "[Episode   786]  total reward: -65680.4105692     steps:  3000, failure\n",
      "[Episode   787]  total reward: -65121.0     steps:  3000, failure\n",
      "[Episode   788]  total reward: -65563.4105692     steps:  3000, failure\n",
      "[Episode   789]  total reward: 944.080847462    steps:    20, success\n",
      "[Episode   790]  total reward: -65635.4105692     steps:  3000, failure\n",
      "[Episode   791]  total reward: -65714.9191525     steps:  3000, failure\n",
      "[Episode   792]  total reward: -65818.9191525     steps:  3000, failure\n",
      "[Episode   793]  total reward: -65594.9191525     steps:  3000, failure\n",
      "[Episode   794]  total reward: -63851.5989095     steps:  3000, failure\n",
      "[Episode   795]  total reward: -54640.5989095     steps:  3000, failure\n",
      "[Episode   796]  total reward: 979.0    steps:    15, success\n",
      "[Episode   797]  total reward: 173.589430828    steps:    54, success\n",
      "[Episode   798]  total reward: -63960.4105692     steps:  3000, failure\n",
      "[Episode   799]  total reward: -65839.9191525     steps:  3000, failure\n",
      "[Episode   800]  total reward: -64232.5989095     steps:  3000, failure\n",
      "[Episode   801]  total reward: -36750.9191525     steps:  3000, failure\n",
      "[Episode   802]  total reward: -64023.5989095     steps:  3000, failure\n",
      "[Episode   803]  total reward: -38920.5989095     steps:  3000, failure\n",
      "[Episode   804]  total reward: -54872.9191525     steps:  3000, failure\n",
      "[Episode   805]  total reward: -58372.9191525     steps:  3000, failure\n",
      "[Episode   806]  total reward: -35902.5989095     steps:  3000, failure\n",
      "[Episode   807]  total reward: -35936.9191525     steps:  3000, failure\n",
      "[Episode   808]  total reward: -36139.4105692     steps:  3000, failure\n",
      "[Episode   809]  total reward: -64907.4105692     steps:  3000, failure\n",
      "[Episode   810]  total reward: -65232.4105692     steps:  3000, failure\n",
      "[Episode   811]  total reward: -65602.9191525     steps:  3000, failure\n",
      "[Episode   812]  total reward: -65329.9191525     steps:  3000, failure\n",
      "[Episode   813]  total reward: -61676.9191525     steps:  3000, failure\n",
      "[Episode   814]  total reward: -64118.4105692     steps:  3000, failure\n",
      "[Episode   815]  total reward: -65695.0     steps:  3000, failure\n",
      "[Episode   816]  total reward: -64891.0     steps:  3000, failure\n",
      "[Episode   817]  total reward: -65415.9191525     steps:  3000, failure\n",
      "[Episode   818]  total reward: -64062.0     steps:  3000, failure\n",
      "[Episode   819]  total reward: -65023.4105692     steps:  3000, failure\n",
      "[Episode   820]  total reward: -50800.9191525     steps:  3000, failure\n",
      "[Episode   821]  total reward: -59584.0     steps:  3000, failure\n",
      "[Episode   822]  total reward: -38963.0     steps:  3000, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   823]  total reward: -55790.0     steps:  3000, failure\n",
      "[Episode   824]  total reward: -35912.5989095     steps:  3000, failure\n",
      "[Episode   825]  total reward: -36161.5989095     steps:  3000, failure\n",
      "[Episode   826]  total reward: -55742.0     steps:  3000, failure\n",
      "[Episode   827]  total reward: -64539.5989095     steps:  3000, failure\n",
      "[Episode   828]  total reward: -36567.0     steps:  3000, failure\n",
      "[Episode   829]  total reward: -36120.0     steps:  3000, failure\n",
      "[Episode   830]  total reward: -39336.9191525     steps:  3000, failure\n",
      "[Episode   831]  total reward: -59774.5989095     steps:  3000, failure\n",
      "[Episode   832]  total reward: -63827.9191525     steps:  3000, failure\n",
      "[Episode   833]  total reward: -58502.0     steps:  3000, failure\n",
      "[Episode   834]  total reward: -35912.0     steps:  3000, failure\n",
      "[Episode   835]  total reward: -54218.0     steps:  3000, failure\n",
      "[Episode   836]  total reward: -44382.0     steps:  3000, failure\n",
      "[Episode   837]  total reward: -64990.0119498     steps:  3000, failure\n",
      "[Episode   838]  total reward: -63769.5989095     steps:  3000, failure\n",
      "[Episode   839]  total reward: -64646.0     steps:  3000, failure\n",
      "[Episode   840]  total reward: -65492.0     steps:  3000, failure\n",
      "[Episode   841]  total reward: -40022.0     steps:  3000, failure\n",
      "[Episode   842]  total reward: -38662.0     steps:  3000, failure\n",
      "[Episode   843]  total reward: -63902.9191525     steps:  3000, failure\n",
      "[Episode   844]  total reward: -65586.5989095     steps:  3000, failure\n",
      "[Episode   845]  total reward: -64534.0     steps:  3000, failure\n",
      "[Episode   846]  total reward: -65632.0     steps:  3000, failure\n",
      "[Episode   847]  total reward: -64852.4105692     steps:  3000, failure\n",
      "[Episode   848]  total reward: -5340.0    steps:   330, success\n",
      "[Episode   849]  total reward: -65645.9191525     steps:  3000, failure\n",
      "[Episode   850]  total reward: -1552.41056917    steps:   132, success\n",
      "[Episode   851]  total reward: -532.410569172    steps:    82, success\n",
      "[Episode   852]  total reward: -64748.4105692     steps:  3000, failure\n",
      "[Episode   853]  total reward: -65703.4105692     steps:  3000, failure\n",
      "[Episode   854]  total reward: -61972.0     steps:  3000, failure\n",
      "[Episode   855]  total reward: -57900.0     steps:  3000, failure\n",
      "[Episode   856]  total reward: -49156.5989095     steps:  3000, failure\n",
      "[Episode   857]  total reward: -54538.9191525     steps:  3000, failure\n",
      "[Episode   858]  total reward: -47699.5989095     steps:  3000, failure\n",
      "[Episode   859]  total reward: -35621.0     steps:  3000, failure\n",
      "[Episode   860]  total reward: -36093.4105692     steps:  3000, failure\n",
      "[Episode   861]  total reward: -62451.5989095     steps:  3000, failure\n",
      "[Episode   862]  total reward: -65645.9191525     steps:  3000, failure\n",
      "[Episode   863]  total reward: -62755.0     steps:  3000, failure\n",
      "[Episode   864]  total reward: -64242.9191525     steps:  3000, failure\n",
      "[Episode   865]  total reward: -35808.9191525     steps:  3000, failure\n",
      "[Episode   866]  total reward: -44143.0     steps:  3000, failure\n",
      "[Episode   867]  total reward: -61960.9191525     steps:  3000, failure\n",
      "[Episode   868]  total reward: -65671.4105692     steps:  3000, failure\n",
      "[Episode   869]  total reward: -65494.9191525     steps:  3000, failure\n",
      "[Episode   870]  total reward: -65557.9191525     steps:  3000, failure\n",
      "[Episode   871]  total reward: -65399.0     steps:  3000, failure\n",
      "[Episode   872]  total reward: -63835.5989095     steps:  3000, failure\n",
      "[Episode   873]  total reward: -65604.0     steps:  3000, failure\n",
      "[Episode   874]  total reward: -40492.0     steps:  3000, failure\n",
      "[Episode   875]  total reward: -65121.4105692     steps:  3000, failure\n",
      "[Episode   876]  total reward: -65595.4105692     steps:  3000, failure\n",
      "[Episode   877]  total reward: -43525.4105692     steps:  3000, failure\n",
      "[Episode   878]  total reward: -60997.0     steps:  3000, failure\n",
      "[Episode   879]  total reward: -65481.0     steps:  3000, failure\n",
      "[Episode   880]  total reward: -63231.0119498     steps:  3000, failure\n",
      "[Episode   881]  total reward: -59236.9191525     steps:  3000, failure\n",
      "[Episode   882]  total reward: -65319.9191525     steps:  3000, failure\n",
      "[Episode   883]  total reward: -65455.4105692     steps:  3000, failure\n",
      "[Episode   884]  total reward: -63004.0     steps:  3000, failure\n",
      "[Episode   885]  total reward: -64432.9191525     steps:  3000, failure\n",
      "[Episode   886]  total reward: -47990.5989095     steps:  3000, failure\n",
      "[Episode   887]  total reward: -61216.5989095     steps:  3000, failure\n",
      "[Episode   888]  total reward: -64635.0     steps:  3000, failure\n",
      "[Episode   889]  total reward: 112.0    steps:    72, success\n",
      "[Episode   890]  total reward: -65242.0     steps:  3000, failure\n",
      "[Episode   891]  total reward: -64324.0     steps:  3000, failure\n",
      "[Episode   892]  total reward: -62005.0     steps:  3000, failure\n",
      "[Episode   893]  total reward: -64921.4105692     steps:  3000, failure\n",
      "[Episode   894]  total reward: -65627.0119498     steps:  3000, failure\n",
      "[Episode   895]  total reward: -62384.4105692     steps:  3000, failure\n",
      "[Episode   896]  total reward: -65295.4105692     steps:  3000, failure\n",
      "[Episode   897]  total reward: -62770.9191525     steps:  3000, failure\n",
      "[Episode   898]  total reward: -55550.0     steps:  3000, failure\n",
      "[Episode   899]  total reward: -37585.0119498     steps:  3000, failure\n",
      "[Episode   900]  total reward: 788.080847462    steps:    66, success\n",
      "[Episode   901]  total reward: -64488.0     steps:  3000, failure\n",
      "[Episode   902]  total reward: -57061.9191525     steps:  3000, failure\n",
      "[Episode   903]  total reward: -43490.0     steps:  3000, failure\n",
      "[Episode   904]  total reward: -50048.9191525     steps:  3000, failure\n",
      "[Episode   905]  total reward: -37841.5989095     steps:  3000, failure\n",
      "[Episode   906]  total reward: -81.9191525376    steps:    88, success\n",
      "[Episode   907]  total reward: -65042.0     steps:  3000, failure\n",
      "[Episode   908]  total reward: -65832.9191525     steps:  3000, failure\n",
      "[Episode   909]  total reward: -65769.9191525     steps:  3000, failure\n",
      "[Episode   910]  total reward: -65529.9191525     steps:  3000, failure\n",
      "[Episode   911]  total reward: -65668.9191525     steps:  3000, failure\n",
      "[Episode   912]  total reward: -63728.0     steps:  3000, failure\n",
      "[Episode   913]  total reward: -65716.0     steps:  3000, failure\n",
      "[Episode   914]  total reward: -64378.0     steps:  3000, failure\n",
      "[Episode   915]  total reward: -59746.0     steps:  3000, failure\n",
      "[Episode   916]  total reward: -36782.0     steps:  3000, failure\n",
      "[Episode   917]  total reward: -59394.0     steps:  3000, failure\n",
      "[Episode   918]  total reward: -36614.0     steps:  3000, failure\n",
      "[Episode   919]  total reward: -65359.4105692     steps:  3000, failure\n",
      "[Episode   920]  total reward: -62736.4105692     steps:  3000, failure\n",
      "[Episode   921]  total reward: -63236.0     steps:  3000, failure\n",
      "[Episode   922]  total reward: -65412.4105692     steps:  3000, failure\n",
      "[Episode   923]  total reward: -44932.4105692     steps:  3000, failure\n",
      "[Episode   924]  total reward: -62994.9191525     steps:  3000, failure\n",
      "[Episode   925]  total reward: -65548.4105692     steps:  3000, failure\n",
      "[Episode   926]  total reward: -65004.0     steps:  3000, failure\n",
      "[Episode   927]  total reward: -64530.5989095     steps:  3000, failure\n",
      "[Episode   928]  total reward: -65803.5989095     steps:  3000, failure\n",
      "[Episode   929]  total reward: -64824.0     steps:  3000, failure\n",
      "[Episode   930]  total reward: -63722.9191525     steps:  3000, failure\n",
      "[Episode   931]  total reward: -56560.9191525     steps:  3000, failure\n",
      "[Episode   932]  total reward: 383.0    steps:    57, success\n",
      "[Episode   933]  total reward: -64838.5989095     steps:  3000, failure\n",
      "[Episode   934]  total reward: -65047.9191525     steps:  3000, failure\n",
      "[Episode   935]  total reward: -60200.0     steps:  3000, failure\n",
      "[Episode   936]  total reward: -62538.0     steps:  3000, failure\n",
      "[Episode   937]  total reward: -55138.9191525     steps:  3000, failure\n",
      "[Episode   938]  total reward: -65527.4105692     steps:  3000, failure\n",
      "[Episode   939]  total reward: -65484.5989095     steps:  3000, failure\n",
      "[Episode   940]  total reward: -41376.9191525     steps:  3000, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   941]  total reward: -63462.5989095     steps:  3000, failure\n",
      "[Episode   942]  total reward: -41122.9191525     steps:  3000, failure\n",
      "[Episode   943]  total reward: -50071.9191525     steps:  3000, failure\n",
      "[Episode   944]  total reward: -65783.4105692     steps:  3000, failure\n",
      "[Episode   945]  total reward: -64962.5989095     steps:  3000, failure\n",
      "[Episode   946]  total reward: -45358.0     steps:  3000, failure\n",
      "[Episode   947]  total reward: -56991.9191525     steps:  3000, failure\n",
      "[Episode   948]  total reward: -63614.0     steps:  3000, failure\n",
      "[Episode   949]  total reward: -8771.0    steps:   487, success\n",
      "[Episode   950]  total reward: -64385.9191525     steps:  3000, failure\n",
      "[Episode   951]  total reward: -65501.9191525     steps:  3000, failure\n",
      "[Episode   952]  total reward: -65305.0119498     steps:  3000, failure\n",
      "[Episode   953]  total reward: -63129.9191525     steps:  3000, failure\n",
      "[Episode   954]  total reward: 754.589430828    steps:    36, success\n",
      "[Episode   955]  total reward: 948.988050249    steps:    29, success\n",
      "[Episode   956]  total reward: -64726.4105692     steps:  3000, failure\n",
      "[Episode   957]  total reward: -65589.4105692     steps:  3000, failure\n",
      "[Episode   958]  total reward: -48458.9191525     steps:  3000, failure\n",
      "[Episode   959]  total reward: -37839.4105692     steps:  3000, failure\n",
      "[Episode   960]  total reward: -65090.9191525     steps:  3000, failure\n",
      "[Episode   961]  total reward: -60752.9191525     steps:  3000, failure\n",
      "[Episode   962]  total reward: -65323.4105692     steps:  3000, failure\n",
      "[Episode   963]  total reward: -65484.0     steps:  3000, failure\n",
      "[Episode   964]  total reward: -62872.9191525     steps:  3000, failure\n",
      "[Episode   965]  total reward: -48278.0     steps:  3000, failure\n",
      "[Episode   966]  total reward: -49452.0     steps:  3000, failure\n",
      "[Episode   967]  total reward: -36850.5989095     steps:  3000, failure\n",
      "[Episode   968]  total reward: -48664.5989095     steps:  3000, failure\n",
      "[Episode   969]  total reward: -53002.0     steps:  3000, failure\n",
      "[Episode   970]  total reward: -35931.9191525     steps:  3000, failure\n",
      "[Episode   971]  total reward: -38721.4105692     steps:  3000, failure\n",
      "[Episode   972]  total reward: -63890.4105692     steps:  3000, failure\n",
      "[Episode   973]  total reward: -63784.0     steps:  3000, failure\n",
      "[Episode   974]  total reward: -65415.9191525     steps:  3000, failure\n",
      "[Episode   975]  total reward: -65849.9191525     steps:  3000, failure\n",
      "[Episode   976]  total reward: -56072.5989095     steps:  3000, failure\n",
      "[Episode   977]  total reward: 984.589430828    steps:    15, success\n",
      "[Episode   978]  total reward: -64454.4105692     steps:  3000, failure\n",
      "[Episode   979]  total reward: -65398.9191525     steps:  3000, failure\n",
      "[Episode   980]  total reward: -45838.0119498     steps:  3000, failure\n",
      "[Episode   981]  total reward: -54927.0119498     steps:  3000, failure\n",
      "[Episode   982]  total reward: -35670.0119498     steps:  3000, failure\n",
      "[Episode   983]  total reward: -56948.0119498     steps:  3000, failure\n",
      "[Episode   984]  total reward: -40852.5989095     steps:  3000, failure\n",
      "[Episode   985]  total reward: -65491.0     steps:  3000, failure\n",
      "[Episode   986]  total reward: -62846.5989095     steps:  3000, failure\n",
      "[Episode   987]  total reward: -65616.0     steps:  3000, failure\n",
      "[Episode   988]  total reward: -8123.41056917    steps:   446, success\n",
      "[Episode   989]  total reward: -49256.5989095     steps:  3000, failure\n",
      "[Episode   990]  total reward: -57376.4105692     steps:  3000, failure\n",
      "[Episode   991]  total reward: -41126.5989095     steps:  3000, failure\n",
      "[Episode   992]  total reward: -47266.5989095     steps:  3000, failure\n",
      "[Episode   993]  total reward: -36505.4105692     steps:  3000, failure\n",
      "[Episode   994]  total reward: -56573.4105692     steps:  3000, failure\n",
      "[Episode   995]  total reward: -65119.4105692     steps:  3000, failure\n",
      "[Episode   996]  total reward: 408.988050249    steps:    72, success\n",
      "[Episode   997]  total reward: 921.589430828    steps:    15, success\n",
      "[Episode   998]  total reward: -1307.0    steps:   119, success\n",
      "[Episode   999]  total reward: -65419.4105692     steps:  3000, failure\n",
      "[Episode  1000]  total reward: -2572.41056917    steps:   222, success\n",
      "[Episode  1001]  total reward: 959.988050249    steps:    19, success\n",
      "[Episode  1002]  total reward: -57902.4105692     steps:  3000, failure\n",
      "[Episode  1003]  total reward: -50251.9191525     steps:  3000, failure\n",
      "[Episode  1004]  total reward: 984.988050249    steps:    11, success\n",
      "[Episode  1005]  total reward: 984.988050249    steps:    11, success\n",
      "[Episode  1006]  total reward: 984.988050249    steps:    11, success\n",
      "[Episode  1007]  total reward: 980.988050249    steps:    12, success\n",
      "[Episode  1008]  total reward: 984.988050249    steps:    11, success\n",
      "[Episode  1009]  total reward: -65126.0119498     steps:  3000, failure\n",
      "[Episode  1010]  total reward: -59243.0119498     steps:  3000, failure\n",
      "[Episode  1011]  total reward: -44212.9191525     steps:  3000, failure\n",
      "[Episode  1012]  total reward: -52192.0     steps:  3000, failure\n",
      "[Episode  1013]  total reward: -61998.0     steps:  3000, failure\n",
      "[Episode  1014]  total reward: -65657.4105692     steps:  3000, failure\n",
      "[Episode  1015]  total reward: -65538.0     steps:  3000, failure\n",
      "[Episode  1016]  total reward: -65530.0     steps:  3000, failure\n",
      "[Episode  1017]  total reward: -53670.5989095     steps:  3000, failure\n",
      "[Episode  1018]  total reward: -61741.5989095     steps:  3000, failure\n",
      "[Episode  1019]  total reward: -56576.4105692     steps:  3000, failure\n",
      "[Episode  1020]  total reward: -53852.5989095     steps:  3000, failure\n",
      "[Episode  1021]  total reward: -53731.0     steps:  3000, failure\n",
      "[Episode  1022]  total reward: -65774.4105692     steps:  3000, failure\n",
      "[Episode  1023]  total reward: -65124.9191525     steps:  3000, failure\n",
      "[Episode  1024]  total reward: -64979.5989095     steps:  3000, failure\n",
      "[Episode  1025]  total reward: -65500.5989095     steps:  3000, failure\n",
      "[Episode  1026]  total reward: -64870.5989095     steps:  3000, failure\n",
      "[Episode  1027]  total reward: -54347.5989095     steps:  3000, failure\n",
      "[Episode  1028]  total reward: -55904.9191525     steps:  3000, failure\n",
      "[Episode  1029]  total reward: -59582.9191525     steps:  3000, failure\n",
      "[Episode  1030]  total reward: -8725.5989095    steps:   477, success\n",
      "[Episode  1031]  total reward: -970.598909495    steps:   163, success\n",
      "[Episode  1032]  total reward: -63559.4105692     steps:  3000, failure\n",
      "[Episode  1033]  total reward: -50818.0     steps:  3000, failure\n",
      "[Episode  1034]  total reward: -44718.5989095     steps:  3000, failure\n",
      "[Episode  1035]  total reward: -40436.0     steps:  3000, failure\n",
      "[Episode  1036]  total reward: -60246.4105692     steps:  3000, failure\n",
      "[Episode  1037]  total reward: -60172.0119498     steps:  3000, failure\n",
      "[Episode  1038]  total reward: -65415.4105692     steps:  3000, failure\n",
      "[Episode  1039]  total reward: -65011.5989095     steps:  3000, failure\n",
      "[Episode  1040]  total reward: -63020.4105692     steps:  3000, failure\n",
      "[Episode  1041]  total reward: -38198.9191525     steps:  3000, failure\n",
      "[Episode  1042]  total reward: -55055.4105692     steps:  3000, failure\n",
      "[Episode  1043]  total reward: -64432.5989095     steps:  3000, failure\n",
      "[Episode  1044]  total reward: -60775.4105692     steps:  3000, failure\n",
      "[Episode  1045]  total reward: 150.0    steps:    58, success\n",
      "[Episode  1046]  total reward: -64864.5989095     steps:  3000, failure\n",
      "[Episode  1047]  total reward: -65675.9191525     steps:  3000, failure\n",
      "[Episode  1048]  total reward: -65248.4105692     steps:  3000, failure\n",
      "[Episode  1049]  total reward: -62227.0119498     steps:  3000, failure\n",
      "[Episode  1050]  total reward: -65429.9191525     steps:  3000, failure\n",
      "[Episode  1051]  total reward: -64237.9191525     steps:  3000, failure\n",
      "[Episode  1052]  total reward: -20333.4105692    steps:  1036, success\n",
      "[Episode  1053]  total reward: -65242.5989095     steps:  3000, failure\n",
      "[Episode  1054]  total reward: -50069.0     steps:  3000, failure\n",
      "[Episode  1055]  total reward: -63715.0     steps:  3000, failure\n",
      "[Episode  1056]  total reward: -58292.9191525     steps:  3000, failure\n",
      "[Episode  1057]  total reward: -63575.4105692     steps:  3000, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode  1058]  total reward: -62105.0     steps:  3000, failure\n",
      "[Episode  1059]  total reward: -50729.0     steps:  3000, failure\n",
      "[Episode  1060]  total reward: -43610.0     steps:  3000, failure\n",
      "[Episode  1061]  total reward: -36808.0     steps:  3000, failure\n",
      "[Episode  1062]  total reward: -63680.9191525     steps:  3000, failure\n",
      "[Episode  1063]  total reward: -55381.0     steps:  3000, failure\n",
      "[Episode  1064]  total reward: -63760.9191525     steps:  3000, failure\n",
      "[Episode  1065]  total reward: -59536.9191525     steps:  3000, failure\n",
      "[Episode  1066]  total reward: -43745.5989095     steps:  3000, failure\n",
      "[Episode  1067]  total reward: -57986.5989095     steps:  3000, failure\n",
      "[Episode  1068]  total reward: -64778.5989095     steps:  3000, failure\n",
      "[Episode  1069]  total reward: -35814.9191525     steps:  3000, failure\n",
      "[Episode  1070]  total reward: -63630.9191525     steps:  3000, failure\n",
      "[Episode  1071]  total reward: -37274.9191525     steps:  3000, failure\n",
      "[Episode  1072]  total reward: -42052.9191525     steps:  3000, failure\n",
      "[Episode  1073]  total reward: -62840.0     steps:  3000, failure\n",
      "[Episode  1074]  total reward: -513.011949751    steps:   107, success\n",
      "[Episode  1075]  total reward: -48903.4105692     steps:  3000, failure\n",
      "[Episode  1076]  total reward: -57808.0     steps:  3000, failure\n",
      "[Episode  1077]  total reward: -65620.0     steps:  3000, failure\n",
      "[Episode  1078]  total reward: -3932.0    steps:   245, success\n",
      "[Episode  1079]  total reward: -12282.0    steps:   661, success\n",
      "[Episode  1080]  total reward: -62638.0     steps:  3000, failure\n",
      "[Episode  1081]  total reward: -63810.5989095     steps:  3000, failure\n",
      "[Episode  1082]  total reward: -62210.0     steps:  3000, failure\n",
      "[Episode  1083]  total reward: -44042.5989095     steps:  3000, failure\n",
      "[Episode  1084]  total reward: -58507.4105692     steps:  3000, failure\n",
      "[Episode  1085]  total reward: -12591.5989095    steps:   686, success\n",
      "[Episode  1086]  total reward: -63372.5989095     steps:  3000, failure\n",
      "[Episode  1087]  total reward: -65702.0     steps:  3000, failure\n",
      "[Episode  1088]  total reward: -60825.0     steps:  3000, failure\n",
      "[Episode  1089]  total reward: -65779.4105692     steps:  3000, failure\n",
      "[Episode  1090]  total reward: -65779.9191525     steps:  3000, failure\n",
      "[Episode  1091]  total reward: -65726.5989095     steps:  3000, failure\n",
      "[Episode  1092]  total reward: -65054.0     steps:  3000, failure\n",
      "[Episode  1093]  total reward: -37280.0     steps:  3000, failure\n",
      "[Episode  1094]  total reward: -63779.0     steps:  3000, failure\n",
      "[Episode  1095]  total reward: -44184.0     steps:  3000, failure\n",
      "[Episode  1096]  total reward: -58550.0     steps:  3000, failure\n",
      "[Episode  1097]  total reward: -64633.0     steps:  3000, failure\n",
      "[Episode  1098]  total reward: -36097.0     steps:  3000, failure\n",
      "[Episode  1099]  total reward: -50064.0     steps:  3000, failure\n",
      "[Episode  1100]  total reward: -42582.0     steps:  3000, failure\n",
      "[Episode  1101]  total reward: -64182.5989095     steps:  3000, failure\n",
      "[Episode  1102]  total reward: -36030.0     steps:  3000, failure\n",
      "[Episode  1103]  total reward: -62308.0     steps:  3000, failure\n",
      "[Episode  1104]  total reward: -64812.9191525     steps:  3000, failure\n",
      "[Episode  1105]  total reward: -55036.5989095     steps:  3000, failure\n",
      "[Episode  1106]  total reward: -64990.0119498     steps:  3000, failure\n",
      "[Episode  1107]  total reward: -36461.0     steps:  3000, failure\n",
      "[Episode  1108]  total reward: -21504.0119498    steps:  1068, success\n",
      "[Episode  1109]  total reward: -63729.0119498     steps:  3000, failure\n",
      "[Episode  1110]  total reward: -64022.5989095     steps:  3000, failure\n",
      "[Episode  1111]  total reward: -38195.4105692     steps:  3000, failure\n",
      "[Episode  1112]  total reward: -60931.4105692    steps:  2884, success\n",
      "[Episode  1113]  total reward: -64790.5989095     steps:  3000, failure\n",
      "[Episode  1114]  total reward: -65150.9191525     steps:  3000, failure\n",
      "[Episode  1115]  total reward: -6934.41056917    steps:   408, success\n",
      "[Episode  1116]  total reward: -65238.5989095     steps:  3000, failure\n",
      "[Episode  1117]  total reward: -46228.0     steps:  3000, failure\n",
      "[Episode  1118]  total reward: -37840.5989095     steps:  3000, failure\n",
      "[Episode  1119]  total reward: -40652.5989095     steps:  3000, failure\n",
      "[Episode  1120]  total reward: -60428.9191525     steps:  3000, failure\n",
      "[Episode  1121]  total reward: -64938.0     steps:  3000, failure\n",
      "[Episode  1122]  total reward: -40446.0     steps:  3000, failure\n",
      "[Episode  1123]  total reward: -64938.0     steps:  3000, failure\n",
      "[Episode  1124]  total reward: -43609.0     steps:  3000, failure\n",
      "[Episode  1125]  total reward: -64857.0119498     steps:  3000, failure\n",
      "[Episode  1126]  total reward: -65206.0     steps:  3000, failure\n",
      "[Episode  1127]  total reward: -2019.41056917    steps:   179, success\n",
      "[Episode  1128]  total reward: -62752.0119498     steps:  3000, failure\n",
      "[Episode  1129]  total reward: -62181.9191525     steps:  3000, failure\n",
      "[Episode  1130]  total reward: -62404.4105692     steps:  3000, failure\n",
      "[Episode  1131]  total reward: -63719.4105692     steps:  3000, failure\n",
      "[Episode  1132]  total reward: 775.589430828    steps:    34, success\n",
      "[Episode  1133]  total reward: -35658.0119498     steps:  3000, failure\n",
      "[Episode  1134]  total reward: -50952.0119498     steps:  3000, failure\n",
      "[Episode  1135]  total reward: -38181.0119498     steps:  3000, failure\n",
      "[Episode  1136]  total reward: -10912.0119498    steps:   627, success\n",
      "[Episode  1137]  total reward: -65464.9191525     steps:  3000, failure\n",
      "[Episode  1138]  total reward: -64535.9191525     steps:  3000, failure\n",
      "[Episode  1139]  total reward: -61966.0     steps:  3000, failure\n",
      "[Episode  1140]  total reward: -65212.0119498     steps:  3000, failure\n",
      "[Episode  1141]  total reward: -63283.0119498     steps:  3000, failure\n",
      "[Episode  1142]  total reward: -56828.9191525     steps:  3000, failure\n",
      "[Episode  1143]  total reward: -65521.0     steps:  3000, failure\n",
      "[Episode  1144]  total reward: -65137.0119498     steps:  3000, failure\n",
      "[Episode  1145]  total reward: -64912.9191525     steps:  3000, failure\n",
      "[Episode  1146]  total reward: -60972.0119498     steps:  3000, failure\n",
      "[Episode  1147]  total reward: -7469.01194975    steps:   500, success\n",
      "[Episode  1148]  total reward: -40172.0119498     steps:  3000, failure\n",
      "[Episode  1149]  total reward: -873.011949751    steps:   106, success\n",
      "[Episode  1150]  total reward: 996.0    steps:    24, success\n",
      "[Episode  1151]  total reward: -36159.4105692     steps:  3000, failure\n",
      "[Episode  1152]  total reward: -644.410569172    steps:   124, success\n",
      "[Episode  1153]  total reward: 997.589430828    steps:    13, success\n",
      "[Episode  1154]  total reward: -35770.0119498     steps:  3000, failure\n",
      "[Episode  1155]  total reward: 995.589430828    steps:    16, success\n",
      "[Episode  1156]  total reward: -35748.0119498     steps:  3000, failure\n",
      "[Episode  1157]  total reward: -35519.0119498     steps:  3000, failure\n",
      "[Episode  1158]  total reward: -37959.0119498     steps:  3000, failure\n",
      "[Episode  1159]  total reward: -61293.0119498     steps:  3000, failure\n",
      "[Episode  1160]  total reward: -37489.9191525     steps:  3000, failure\n",
      "[Episode  1161]  total reward: 793.589430828    steps:    27, success\n",
      "[Episode  1162]  total reward: -64218.5989095     steps:  3000, failure\n",
      "[Episode  1163]  total reward: -56123.9191525     steps:  3000, failure\n",
      "[Episode  1164]  total reward: -65718.0119498     steps:  3000, failure\n",
      "[Episode  1165]  total reward: -65600.5989095     steps:  3000, failure\n",
      "[Episode  1166]  total reward: 89.589430828    steps:   101, success\n",
      "[Episode  1167]  total reward: -37438.0119498     steps:  3000, failure\n",
      "[Episode  1168]  total reward: -43647.5989095     steps:  3000, failure\n",
      "[Episode  1169]  total reward: -65332.0     steps:  3000, failure\n",
      "[Episode  1170]  total reward: 414.080847462    steps:    92, success\n",
      "[Episode  1171]  total reward: -35812.0119498     steps:  3000, failure\n",
      "[Episode  1172]  total reward: 976.988050249    steps:    21, success\n",
      "[Episode  1173]  total reward: -54444.0119498     steps:  3000, failure\n",
      "[Episode  1174]  total reward: -65447.9191525     steps:  3000, failure\n",
      "[Episode  1175]  total reward: -46447.0119498     steps:  3000, failure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode  1176]  total reward: -57927.0     steps:  3000, failure\n",
      "[Episode  1177]  total reward: -41942.0119498     steps:  3000, failure\n",
      "[Episode  1178]  total reward: -55004.4105692     steps:  3000, failure\n",
      "[Episode  1179]  total reward: -60663.5989095     steps:  3000, failure\n",
      "[Episode  1180]  total reward: -62517.9191525     steps:  3000, failure\n",
      "[Episode  1181]  total reward: -46219.4105692     steps:  3000, failure\n",
      "[Episode  1182]  total reward: -48324.5989095     steps:  3000, failure\n",
      "[Episode  1183]  total reward: -62076.0119498     steps:  3000, failure\n",
      "[Episode  1184]  total reward: -64093.4105692     steps:  3000, failure\n",
      "[Episode  1185]  total reward: -50889.0     steps:  3000, failure\n",
      "[Episode  1186]  total reward: -62278.9191525     steps:  3000, failure\n",
      "[Episode  1187]  total reward: -65290.0     steps:  3000, failure\n",
      "[Episode  1188]  total reward: -63246.9191525     steps:  3000, failure\n",
      "[Episode  1189]  total reward: -64966.0     steps:  3000, failure\n",
      "[Episode  1190]  total reward: -63943.4105692     steps:  3000, failure\n",
      "[Episode  1191]  total reward: -6134.5989095    steps:   470, success\n",
      "[Episode  1192]  total reward: -14643.9191525    steps:   802, success\n",
      "[Episode  1193]  total reward: -42010.9191525     steps:  3000, failure\n",
      "[Episode  1194]  total reward: -36228.0     steps:  3000, failure\n",
      "[Episode  1195]  total reward: -65082.5989095     steps:  3000, failure\n",
      "[Episode  1196]  total reward: -60981.4105692     steps:  3000, failure\n",
      "[Episode  1197]  total reward: -2843.0    steps:   224, success\n",
      "[Episode  1198]  total reward: -65239.4105692     steps:  3000, failure\n",
      "[Episode  1199]  total reward: -62174.0     steps:  3000, failure\n",
      "[Episode  1200]  total reward: -62058.5989095     steps:  3000, failure\n",
      "[Episode  1201]  total reward: -36053.4105692     steps:  3000, failure\n",
      "[Episode  1202]  total reward: -62245.4105692     steps:  3000, failure\n",
      "[Episode  1203]  total reward: -62565.4105692     steps:  3000, failure\n",
      "[Episode  1204]  total reward: -63915.4105692     steps:  3000, failure\n",
      "[Episode  1205]  total reward: -59818.9191525     steps:  3000, failure\n",
      "[Episode  1206]  total reward: -57144.4105692     steps:  3000, failure\n",
      "[Episode  1207]  total reward: -65520.5989095     steps:  3000, failure\n",
      "[Episode  1208]  total reward: -64882.0     steps:  3000, failure\n",
      "[Episode  1209]  total reward: -65234.9191525     steps:  3000, failure\n",
      "[Episode  1210]  total reward: -62379.0     steps:  3000, failure\n",
      "[Episode  1211]  total reward: -58112.0     steps:  3000, failure\n",
      "[Episode  1212]  total reward: -65396.5989095     steps:  3000, failure\n",
      "[Episode  1213]  total reward: -63941.5989095     steps:  3000, failure\n",
      "[Episode  1214]  total reward: -63757.9191525     steps:  3000, failure\n",
      "[Episode  1215]  total reward: 151.0    steps:    83, success\n",
      "[Episode  1216]  total reward: -64011.5989095     steps:  3000, failure\n",
      "[Episode  1217]  total reward: 987.988050249    steps:    18, success\n",
      "[Episode  1218]  total reward: -52570.0     steps:  3000, failure\n",
      "[Episode  1219]  total reward: -36256.5989095     steps:  3000, failure\n",
      "[Episode  1220]  total reward: -26604.9191525    steps:  1367, success\n",
      "[Episode  1221]  total reward: -63395.0     steps:  3000, failure\n",
      "[Episode  1222]  total reward: -63871.0     steps:  3000, failure\n",
      "[Episode  1223]  total reward: -64007.9191525     steps:  3000, failure\n",
      "[Episode  1224]  total reward: -36662.5989095     steps:  3000, failure\n",
      "[Episode  1225]  total reward: -36682.5989095     steps:  3000, failure\n",
      "[Episode  1226]  total reward: -63290.0     steps:  3000, failure\n",
      "[Episode  1227]  total reward: -5172.41056917    steps:   439, success\n",
      "[Episode  1228]  total reward: -9441.41056917    steps:   486, success\n",
      "[Episode  1229]  total reward: -64566.4105692     steps:  3000, failure\n",
      "[Episode  1230]  total reward: -4967.41056917    steps:   285, success\n",
      "[Episode  1231]  total reward: -65370.0     steps:  3000, failure\n",
      "[Episode  1232]  total reward: -58724.9191525     steps:  3000, failure\n",
      "[Episode  1233]  total reward: -65627.4105692     steps:  3000, failure\n",
      "[Episode  1234]  total reward: -61857.9191525     steps:  3000, failure\n",
      "[Episode  1235]  total reward: -65502.0     steps:  3000, failure\n",
      "[Episode  1236]  total reward: -65153.0     steps:  3000, failure\n",
      "[Episode  1237]  total reward: -38106.4105692     steps:  3000, failure\n",
      "[Episode  1238]  total reward: -36310.5989095     steps:  3000, failure\n",
      "[Episode  1239]  total reward: -64161.4105692     steps:  3000, failure\n",
      "[Episode  1240]  total reward: -65569.5989095     steps:  3000, failure\n",
      "[Episode  1241]  total reward: -65243.5989095     steps:  3000, failure\n",
      "[Episode  1242]  total reward: -64244.9191525     steps:  3000, failure\n",
      "[Episode  1243]  total reward: -57094.9191525     steps:  3000, failure\n",
      "[Episode  1244]  total reward: -65198.9191525     steps:  3000, failure\n",
      "[Episode  1245]  total reward: -64679.4105692     steps:  3000, failure\n",
      "[Episode  1246]  total reward: -64328.5989095     steps:  3000, failure\n",
      "[Episode  1247]  total reward: -62867.9191525     steps:  3000, failure\n",
      "[Episode  1248]  total reward: -41132.5989095     steps:  3000, failure\n",
      "[Episode  1249]  total reward: -45772.5989095     steps:  3000, failure\n",
      "[Episode  1250]  total reward: -45234.9191525     steps:  3000, failure\n",
      "[Episode  1251]  total reward: -62102.5989095     steps:  3000, failure\n",
      "[Episode  1252]  total reward: -65296.0     steps:  3000, failure\n",
      "[Episode  1253]  total reward: -65855.4105692     steps:  3000, failure\n",
      "[Episode  1254]  total reward: -63500.9191525     steps:  3000, failure\n",
      "[Episode  1255]  total reward: -63170.9191525     steps:  3000, failure\n",
      "[Episode  1256]  total reward: -35952.0     steps:  3000, failure\n",
      "[Episode  1257]  total reward: -65120.0119498     steps:  3000, failure\n",
      "[Episode  1258]  total reward: -64768.5989095     steps:  3000, failure\n",
      "[Episode  1259]  total reward: -65742.5989095     steps:  3000, failure\n",
      "[Episode  1260]  total reward: -65655.9191525     steps:  3000, failure\n",
      "[Episode  1261]  total reward: -64926.9191525     steps:  3000, failure\n",
      "[Episode  1262]  total reward: -60537.9191525     steps:  3000, failure\n",
      "[Episode  1263]  total reward: -65827.0     steps:  3000, failure\n",
      "[Episode  1264]  total reward: -63408.5989095     steps:  3000, failure\n",
      "[Episode  1265]  total reward: -65032.9191525     steps:  3000, failure\n",
      "[Episode  1266]  total reward: -64818.5989095     steps:  3000, failure\n",
      "[Episode  1267]  total reward: 857.589430828    steps:    18, success\n",
      "[Episode  1268]  total reward: 773.988050249    steps:    33, success\n",
      "[Episode  1269]  total reward: -62063.5989095     steps:  3000, failure\n",
      "[Episode  1270]  total reward: -64216.9191525     steps:  3000, failure\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-be20509cbe45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-be20509cbe45>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACTION_NUM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maction_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# convert to index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                     \u001b[0mact_candi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_candi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     '''\n",
      "\u001b[0;32m/home/hotae319/rl_test/dqn_cooperation.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m       \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m       \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((t, v))\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m       \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m       \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_as_tf_output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/c_api_util.pyc\u001b[0m in \u001b[0;36mtf_output\u001b[0;34m(c_op, index)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mWrapped\u001b[0m \u001b[0mTF_Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hotae319/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_TF_Output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Plotting setting\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import dqn_cooperation\n",
    "from collections import deque\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Create New environment with transition law\n",
    "ACTION_NUM = 5\n",
    "INPUT_SIZE = 10\n",
    "OUTPUT_SIZE = ACTION_NUM**2\n",
    "VEL = 0.5\n",
    "TIME_GAP = 1\n",
    "MAP_SIZE = 7\n",
    "def annealing_epsilon(episode, min_e, max_e, target_episode):\n",
    "\n",
    "    slope = (min_e - max_e) / (target_episode)\n",
    "    intercept = max_e\n",
    "\n",
    "    return max(min_e, slope * episode + intercept)\n",
    "\n",
    "class new_env:     \n",
    "    def create_env(self, arg_state=[1.,2.,1.,3.], g_pos=[5.,5.], obs_pos1=[2.,2.], obs_pos2=[3.,4.], obs_size=5):\n",
    "        self.state = np.array(arg_state+g_pos+obs_pos1+obs_pos2) # reset\n",
    "        self.n_state = np.array(arg_state+g_pos+obs_pos1+obs_pos2)\n",
    "        self.obstacle_size = obs_size\n",
    "        return self.state, self.obstacle_size\n",
    "    #def add_obs(self, obs_pos), we postpone this \n",
    "    \n",
    "    def next_step(self, arg_state, arg_action):\n",
    "\n",
    "        self._fail = False\n",
    "        self.reward = 0\n",
    "        # convert to each action\n",
    "        arg_action1 = arg_action // ACTION_NUM\n",
    "        arg_action2 = arg_action - ACTION_NUM*arg_action1\n",
    "        '''position update through action\n",
    "        UP = 0, DOWN = 1, LEFT = 2, RIGHT = 3'''        \n",
    "        # agent 1\n",
    "        if arg_action1 == 0:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,1,0,0])*VEL*TIME_GAP\n",
    "        elif arg_action1 == 1:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,-1,0,0])*VEL*TIME_GAP\n",
    "        elif arg_action1 == 2:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([-1,0,0,0])*VEL*TIME_GAP\n",
    "        elif arg_action1 == 3:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([1,0,0,0])*VEL*TIME_GAP\n",
    "        else:\n",
    "            self.n_state[0:4] = arg_state[0:4] # stop        \n",
    "        # agent 2  \n",
    "        if arg_action2 == 0:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,0,0,1])*VEL*TIME_GAP\n",
    "        elif arg_action2 == 1:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,0,0,-1])*VEL*TIME_GAP\n",
    "        elif arg_action2 == 2:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,0,-1,0])*VEL*TIME_GAP\n",
    "        elif arg_action1 == 3:\n",
    "            self.n_state[0:4] = arg_state[0:4] + np.array([0,0,1,0])*VEL*TIME_GAP      \n",
    "        else:\n",
    "            self.n_state[0:4] = arg_state[0:4] # stop   \n",
    "            \n",
    "        '''get the reward'''\n",
    "        if np.linalg.norm((self.n_state[0:2]+self.n_state[2:4])/2-self.n_state[4:6])!=0:\n",
    "            self.reward = (1/np.linalg.norm((self.n_state[0:2]+self.n_state[2:4])/2-self.n_state[4:6])-\\\n",
    "            1/np.linalg.norm((arg_state[0:2]+arg_state[2:4])/2-self.n_state[4:6]))*100\n",
    "        if np.linalg.norm(self.n_state[0:2]-self.n_state[6:8])<1 or np.linalg.norm(self.n_state[2:4]-self.n_state[6:8])<1:\n",
    "            self.reward = self.reward-1 # collision\n",
    "        if np.linalg.norm(self.n_state[0:2]-self.n_state[8:10])<1 or np.linalg.norm(self.n_state[2:4]-self.n_state[8:10])<1:\n",
    "            self.reward = self.reward-1 # collision\n",
    "        if np.linalg.norm((self.n_state[0:2]+self.n_state[2:4])/2-self.n_state[4:6])<1 and np.linalg.norm(self.n_state[0:2]-self.n_state[2:4])<3: # approximately set condition\n",
    "            self.reward = self.reward + 1000 # achieve goal\n",
    "            self._fail = True\n",
    "        if np.linalg.norm(self.n_state[0:2]-self.n_state[2:4])>2.5:\n",
    "            self.reward = self.reward-2 # drop the object\n",
    "            #self._fail = True     \n",
    "        if any(x<0 for x in self.n_state):            \n",
    "            self.reward = self.reward-10 # away from the map\n",
    "            #self._fail = True   \n",
    "        if any(x>MAP_SIZE for x in self.n_state):            \n",
    "            self.reward = self.reward-10 # away from the map\n",
    "            #self._fail = True     \n",
    "        return self.n_state, self.reward, self._fail\n",
    "    \n",
    "#env = new_env() \n",
    "#state, g_pos, o_pos, o_size = env.create_env() # set the enviornment\n",
    "DISCOUNT_RATE = 0.98\n",
    "REPLAY_MEMORY = 10000\n",
    "BATCH_SIZE = 50\n",
    "MAX_EPI = 6000\n",
    "MAX_STEP = 3000\n",
    "# minimum epsilon for epsilon greedy\n",
    "MIN_E = 0.1\n",
    "# epsilon will be `MIN_E` at `EPSILON_DECAYING_STEP`\n",
    "EPSILON_DECAYING_STEP = MAX_STEP * 0.2\n",
    "TARGET_UPDATE_FQ = 20\n",
    "\n",
    "def train_minibatch(mainDQN, targetDQN, minibatch):\n",
    "    state_array = np.array([x[0] for x in minibatch])\n",
    "    action_array = np.array([x[1] for x in minibatch]) # [ x among 0~24] * BATCH_SIZE\n",
    "    reward_array = np.array([x[2] for x in minibatch])\n",
    "    n_state_array = np.array([x[3] for x in minibatch])\n",
    "    _fail_array = np.array([x[4] for x in minibatch])    \n",
    "    \n",
    "    X_batch = state_array   \n",
    "    Y_batch = mainDQN.predict(state_array) # 25 elements * BATCH_SIZE \n",
    "    \n",
    "    Q_target = reward_array + DISCOUNT_RATE*np.max(targetDQN.predict(n_state_array),axis=1)*~_fail_array # if fail, Q = reward\n",
    "    \n",
    "    Y_batch[np.arange(len(X_batch)), action_array] = Q_target\n",
    "    \n",
    "    # Train\n",
    "    cost_batch, _ = mainDQN.update(X_batch, Y_batch)\n",
    "    return cost_batch\n",
    "\n",
    "def get_copy_var_ops(dest_scope_name = \"target\", src_scope_name = \"main\"):\n",
    "    op_holder = []\n",
    "    \n",
    "    src_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=src_scope_name)\n",
    "    dest_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=dest_scope_name)\n",
    "\n",
    "    for src_var, dest_var in zip(src_vars, dest_vars):\n",
    "        op_holder.append(dest_var.assign(src_var.value()))\n",
    "\n",
    "    return op_holder\n",
    "\n",
    "\n",
    "def main():\n",
    "    replay_buffer = deque(maxlen=REPLAY_MEMORY) # detract element from both sides    \n",
    "    total_reward_buffer = []\n",
    "    with tf.Session() as sess:\n",
    "        mainDQN = dqn_cooperation.DQN(sess, INPUT_SIZE, OUTPUT_SIZE, name = \"main\")\n",
    "        mainDQN.build_network(32,64,0.005)\n",
    "        targetDQN = dqn_cooperation.DQN(sess, INPUT_SIZE, OUTPUT_SIZE, name = \"target\")\n",
    "        targetDQN.build_network(32,64,0.005)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        # initial copy main q -> target q\n",
    "        copy_ops = get_copy_var_ops(dest_scope_name = \"target\", src_scope_name = \"main\")\n",
    "        sess.run(copy_ops)\n",
    "        \n",
    "        reward_accum_last100 = 0\n",
    "        reward_sum = 0        \n",
    "\n",
    "        game = ENV(MAP_SIZE, [2,2], [3,4], [1,2,1,3], [5,5])\n",
    "        game.render_env()\n",
    "        \n",
    "        for episode in range(MAX_EPI):\n",
    "            \n",
    "            '''\n",
    "            if episode < 100:\n",
    "                e = 0.3\n",
    "            e = 0.05\n",
    "            '''\n",
    "            _fail = False\n",
    "            step_count = 0 # how many moves included in an episode\n",
    "            env1 = new_env()\n",
    "            state, _= env1.create_env() # get only state\n",
    "            \n",
    "            \n",
    "            reward_sum = 0      \n",
    "            goal_ = True\n",
    "            while not _fail:\n",
    "                e = annealing_epsilon(step_count, MIN_E, 1.0, EPSILON_DECAYING_STEP)\n",
    "                # after sufficient learning, we present the game scene\n",
    "                if episode > MAX_EPI-2:\n",
    "                    game.update(state)\n",
    "                    game.render_env()\n",
    "                    \n",
    "                step_count += 1\n",
    "                if np.random.rand()< e:\n",
    "                    action_l = random.sample(np.arange(ACTION_NUM),2) # choose up, down, left, right, stop\n",
    "                    action = action_l[0]*(ACTION_NUM) + action_l[1] # convert to index\n",
    "                else:\n",
    "                    act_candi = mainDQN.predict(state)\n",
    "                    action = np.argmax(act_candi)   \n",
    "                    '''\n",
    "                    dd_predict = mainDQN.predict(state).flatten()\n",
    "                    aa = np.max(dd_predict)\n",
    "                    max_indx, = np.where(dd_predict==aa)                    \n",
    "                    action = random.sample(max_indx,1)[0]\n",
    "                    '''\n",
    "                \n",
    "                n_state, reward, _fail = env1.next_step(state, action) # have to input the action \n",
    "                # if count >30, stop that episode and start new episode\n",
    "                if step_count >MAX_STEP-1:\n",
    "                    #reward = -30\n",
    "                    _fail = True\n",
    "                    goal_ = False\n",
    "                    \n",
    "                reward_sum += reward    # sum total reward and penalty about long time(-0.5)                                  \n",
    "                replay_buffer.append((state, action, reward, n_state, _fail)) #resolve the correlation                \n",
    "                state = n_state\n",
    "                \n",
    "                # train minibatch of main Q-NET and update the target Q-network from main Q-NET\n",
    "                if len(replay_buffer)>BATCH_SIZE*4:\n",
    "                    minibatch = random.sample(replay_buffer, BATCH_SIZE)                    \n",
    "                    train_minibatch(mainDQN, targetDQN, minibatch)\n",
    "                if step_count % TARGET_UPDATE_FQ == 0:\n",
    "                    sess.run(copy_ops)\n",
    "                    \n",
    "            total_reward_buffer.append(reward_sum)  \n",
    "            if goal_ == True:\n",
    "                print(\"[Episode {:>5}]  total reward: {:>5}    steps: {:>5}, success\".format(episode, reward_sum, step_count))\n",
    "            else:\n",
    "                print(\"[Episode {:>5}]  total reward: {:>5}     steps: {:>5}, failure\".format(episode, reward_sum, step_count))\n",
    "    #print(\"Success ratio: {}\".format(reward_accum_last100/100))\n",
    "        fig1 =plt.figure()\n",
    "        plt.plot(range(MAX_EPI), total_reward_buffer)\n",
    "        plt.show()\n",
    "    # save model\n",
    "    '''\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"./dqn_multi_action.ckpt\")\n",
    "    '''\n",
    "    \n",
    "            \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()    \n",
    "    end = time.time()-start\n",
    "    print(end)       \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
